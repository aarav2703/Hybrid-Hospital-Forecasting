{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed49bf14",
   "metadata": {},
   "source": [
    "# Hospital Forecasting Pipeline: Architecture & Experimental Design\n",
    "\n",
    "## Objective\n",
    "Develop a generalizable hierarchical forecasting system for hospital capacity planning that integrates classical baselines with machine learning approaches while maintaining temporal integrity and handling heterogeneous facility scales.\n",
    "\n",
    "## Datasets & Temporal Configuration\n",
    "- **Hospital Dataset** (primary): monthly aggregates, H∈{6,12} months\n",
    "- **Tourism & Electricity** (auxiliary): exploratory benchmarks\n",
    "\n",
    "## Core Principles\n",
    "1. **Temporal Leakage Prevention**: rolling-origin backtest with strict train/test cutoffs\n",
    "2. **Bias-Variance Tradeoff Management**: segmentation by facility volume to reduce variance across heterogeneous scales\n",
    "3. **Cold-Start Handling**: minimum training window (48 months) ensures stable feature estimation\n",
    "4. **Residual Analysis**: compute and track error distributions for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146a2b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 .tsf files:\n",
      "\n",
      "electricity_weekly_dataset.tsf\n",
      "hospital_dataset.tsf\n",
      "tourism_monthly_dataset.tsf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Enumerate all available time-series files in the workspace\n",
    "tsf_files = [f for f in os.listdir('.') if f.lower().endswith('.tsf')]\n",
    "tsf_files.sort()\n",
    "\n",
    "print(f\"Found {len(tsf_files)} .tsf files:\\n\")\n",
    "for f in tsf_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9927d",
   "metadata": {},
   "source": [
    "## Cell 2: Metadata Inspection & Format Validation\n",
    "\n",
    "### Technical Rationale\n",
    "The Monash Time-Series Format (TSF) is a human-readable interchange format for heterogeneous forecasting datasets. Before ingesting 50k+ series rows, we validate:\n",
    "- Metadata consistency (frequency, horizon, missing-value indicator)\n",
    "- Attribute schema alignment\n",
    "- Numeric parsing robustness on a sample (prevents downstream surprises)\n",
    "\n",
    "This lightweight inspection runs once and prevents re-scanning the entire file during feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9294179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "FILE: hospital_dataset.tsf\n",
      "------------------------------------------------------------------------------------------\n",
      "@relation: Hospital\n",
      "@frequency: monthly\n",
      "@missing: false\n",
      "@equallength: true\n",
      "\n",
      "@attributes:\n",
      "  - series_name (string)\n",
      "  - start_timestamp (date)\n",
      "\n",
      "Data scan (limited):\n",
      "  Series rows scanned: 767\n",
      "  Series length min/median/max: 84 / 84 / 84\n",
      "  Numeric parse failures (sampled values): 0\n",
      "\n",
      "Preview:\n",
      "  - series_name=T1 | start_timestamp=2000-01-01 00-00-00\n",
      "  - series_name=T2 | start_timestamp=2000-01-01 00-00-00\n",
      "  - series_name=T3 | start_timestamp=2000-01-01 00-00-00\n",
      "==========================================================================================\n",
      "FILE: tourism_monthly_dataset.tsf\n",
      "------------------------------------------------------------------------------------------\n",
      "@relation: Tourism\n",
      "@frequency: monthly\n",
      "@horizon: 24\n",
      "@missing: false\n",
      "@equallength: false\n",
      "\n",
      "@attributes:\n",
      "  - series_name (string)\n",
      "  - start_timestamp (date)\n",
      "\n",
      "Data scan (limited):\n",
      "  Series rows scanned: 366\n",
      "  Series length min/median/max: 91 / 330 / 333\n",
      "  Numeric parse failures (sampled values): 0\n",
      "\n",
      "Preview:\n",
      "  - series_name=T1 | start_timestamp=1979-01-01 00-00-00\n",
      "  - series_name=T2 | start_timestamp=1979-01-01 00-00-00\n",
      "  - series_name=T3 | start_timestamp=1985-01-01 00-00-00\n",
      "==========================================================================================\n",
      "FILE: electricity_weekly_dataset.tsf\n",
      "------------------------------------------------------------------------------------------\n",
      "@relation: Electricity\n",
      "@frequency: weekly\n",
      "@horizon: 8\n",
      "@missing: false\n",
      "@equallength: true\n",
      "\n",
      "@attributes:\n",
      "  - series_name (string)\n",
      "  - start_timestamp (date)\n",
      "\n",
      "Data scan (limited):\n",
      "  Series rows scanned: 321\n",
      "  Series length min/median/max: 156 / 156 / 156\n",
      "  Numeric parse failures (sampled values): 0\n",
      "\n",
      "Preview:\n",
      "  - series_name=T1 | start_timestamp=2012-01-01 00-00-00\n",
      "  - series_name=T2 | start_timestamp=2012-01-01 00-00-00\n",
      "  - series_name=T3 | start_timestamp=2012-01-01 00-00-00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "TSF_FILES = [\n",
    "    \"hospital_dataset.tsf\",\n",
    "    \"tourism_monthly_dataset.tsf\",\n",
    "    \"electricity_weekly_dataset.tsf\",\n",
    "]\n",
    "\n",
    "def parse_tsf(filepath, max_series_preview=3):\n",
    "    \"\"\"\n",
    "    Stream-parse TSF metadata and sample data without loading entire file into memory.\n",
    "    Returns schema (attributes), temporal config (@frequency, @horizon), and series length distribution.\n",
    "    \"\"\"\n",
    "    meta = {}\n",
    "    attributes = []\n",
    "    header_comments = []\n",
    "    in_data = False\n",
    "    series_lengths = []\n",
    "    series_names_preview = []\n",
    "    start_timestamps_preview = []\n",
    "    numeric_parse_failures = 0\n",
    "\n",
    "    attr_pat = re.compile(r\"^@attribute\\s+(\\S+)\\s+(\\S+)\", re.IGNORECASE)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line.startswith(\"#\") and not in_data:\n",
    "                header_comments.append(line)\n",
    "                continue\n",
    "\n",
    "            if line.lower().startswith(\"@data\"):\n",
    "                in_data = True\n",
    "                continue\n",
    "\n",
    "            if not in_data:\n",
    "                if line.lower().startswith(\"@attribute\"):\n",
    "                    m = attr_pat.match(line)\n",
    "                    if m:\n",
    "                        attributes.append((m.group(1), m.group(2)))\n",
    "                    continue\n",
    "\n",
    "                if line.startswith(\"@\"):\n",
    "                    parts = line.split(None, 1)\n",
    "                    key = parts[0].lstrip(\"@\").strip().lower()\n",
    "                    val = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "                    meta[key] = val\n",
    "                continue\n",
    "\n",
    "            # Parse data row: series_name:start_timestamp:val1,val2,val3,...\n",
    "            if in_data:\n",
    "                if len(series_lengths) >= 5000 and max_series_preview == 0:\n",
    "                    break\n",
    "\n",
    "                parts = line.split(\":\", 2)\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "\n",
    "                sname = parts[0]\n",
    "                series_names_preview.append(sname) if len(series_names_preview) < max_series_preview else None\n",
    "\n",
    "                if len(parts) == 2:\n",
    "                    values_str = parts[1]\n",
    "                else:\n",
    "                    ts = parts[1]\n",
    "                    values_str = parts[2]\n",
    "                    if len(start_timestamps_preview) < max_series_preview:\n",
    "                        start_timestamps_preview.append(ts)\n",
    "\n",
    "                values = [v.strip() for v in values_str.split(\",\") if v.strip() != \"\"]\n",
    "                series_lengths.append(len(values))\n",
    "\n",
    "                # Validate numeric parsability on sample\n",
    "                for v in values[:20]:\n",
    "                    try:\n",
    "                        float(v)\n",
    "                    except:\n",
    "                        numeric_parse_failures += 1\n",
    "\n",
    "    summary = {\n",
    "        \"file\": os.path.basename(filepath),\n",
    "        \"meta\": meta,\n",
    "        \"attributes\": attributes,\n",
    "        \"header_comment_lines\": len(header_comments),\n",
    "        \"series_count_estimate\": len(series_lengths),\n",
    "        \"series_length_min\": min(series_lengths) if series_lengths else None,\n",
    "        \"series_length_median\": (sorted(series_lengths)[len(series_lengths)//2] if series_lengths else None),\n",
    "        \"series_length_max\": max(series_lengths) if series_lengths else None,\n",
    "        \"numeric_parse_failures_in_sample\": numeric_parse_failures,\n",
    "        \"series_name_preview\": series_names_preview[:max_series_preview],\n",
    "        \"start_timestamp_preview\": start_timestamps_preview[:max_series_preview],\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "def print_summary(s):\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"FILE: {s['file']}\")\n",
    "    print(\"-\" * 90)\n",
    "\n",
    "    for k in [\"relation\", \"frequency\", \"horizon\", \"missing\", \"equallength\"]:\n",
    "        if k in s[\"meta\"]:\n",
    "            print(f\"@{k}: {s['meta'][k]}\")\n",
    "    other_keys = [k for k in s[\"meta\"].keys() if k not in {\"relation\",\"frequency\",\"horizon\",\"missing\",\"equallength\"}]\n",
    "    if other_keys:\n",
    "        print(\"Other @meta:\")\n",
    "        for k in sorted(other_keys):\n",
    "            print(f\"  @{k}: {s['meta'][k]}\")\n",
    "\n",
    "    print(\"\\n@attributes:\")\n",
    "    if s[\"attributes\"]:\n",
    "        for name, typ in s[\"attributes\"]:\n",
    "            print(f\"  - {name} ({typ})\")\n",
    "    else:\n",
    "        print(\"  (none found)\")\n",
    "\n",
    "    print(\"\\nData scan (limited):\")\n",
    "    print(f\"  Series rows scanned: {s['series_count_estimate']}\")\n",
    "    print(f\"  Series length min/median/max: {s['series_length_min']} / {s['series_length_median']} / {s['series_length_max']}\")\n",
    "    print(f\"  Numeric parse failures (sampled values): {s['numeric_parse_failures_in_sample']}\")\n",
    "\n",
    "    print(\"\\nPreview:\")\n",
    "    for i, name in enumerate(s[\"series_name_preview\"]):\n",
    "        ts = s[\"start_timestamp_preview\"][i] if i < len(s[\"start_timestamp_preview\"]) else \"(no timestamp field)\"\n",
    "        print(f\"  - series_name={name} | start_timestamp={ts}\")\n",
    "\n",
    "# Execute metadata inspection across all configured datasets\n",
    "for fn in TSF_FILES:\n",
    "    path = Path(\"./\") / fn\n",
    "    if not path.exists():\n",
    "        print(f\"[MISSING] {fn} not found in current directory.\")\n",
    "        continue\n",
    "    summary = parse_tsf(path, max_series_preview=3)\n",
    "    print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73464b",
   "metadata": {},
   "source": [
    "## Cell 3: Temporal Data Ingestion & Frequency Alignment\n",
    "\n",
    "### Technical Rationale\n",
    "TSF format encodes series as text; we convert to a normalized long-form DataFrame with:\n",
    "- **Timezone Consistency**: convert all timestamps to UTC-naive to prevent comparison errors during rolling backtest\n",
    "- **Frequency-Aware Interpolation**: respect declared frequency (monthly, weekly) when reconstructing timestamps from sparse start_ts\n",
    "- **Missing-Value Handling**: NaN propagation through numeric coercion (pandas' `to_numeric(..., coerce=True)`)\n",
    "\n",
    "This ensures that downstream feature engineering (lags, rolling statistics) aligns correctly with calendar boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39cfe027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "hospital_dataset.tsf\n",
      "shape: (64428, 4)\n",
      "columns: ['dataset', 'series_name', 'timestamp', 'y']\n",
      "n_series: 767\n",
      "date_range: 2000-01-01 00:00:00+00:00 -> 2006-12-01 00:00:00+00:00\n",
      "missing_y: 0\n",
      "                dataset series_name                 timestamp   y\n",
      "0  hospital_dataset.tsf          T1 2000-01-01 00:00:00+00:00  27\n",
      "1  hospital_dataset.tsf          T1 2000-02-01 00:00:00+00:00  16\n",
      "2  hospital_dataset.tsf          T1 2000-03-01 00:00:00+00:00  18\n",
      "================================================================================\n",
      "tourism_monthly_dataset.tsf\n",
      "shape: (109280, 4)\n",
      "columns: ['dataset', 'series_name', 'timestamp', 'y']\n",
      "n_series: 366\n",
      "date_range: 1979-01-01 00:00:00+00:00 -> 2007-09-01 00:00:00+00:00\n",
      "missing_y: 0\n",
      "                       dataset series_name                 timestamp  \\\n",
      "0  tourism_monthly_dataset.tsf          T1 1979-01-01 00:00:00+00:00   \n",
      "1  tourism_monthly_dataset.tsf          T1 1979-02-01 00:00:00+00:00   \n",
      "2  tourism_monthly_dataset.tsf          T1 1979-03-01 00:00:00+00:00   \n",
      "\n",
      "           y  \n",
      "0  1149.8700  \n",
      "1  1053.8002  \n",
      "2  1388.8798  \n",
      "================================================================================\n",
      "electricity_weekly_dataset.tsf\n",
      "shape: (50076, 4)\n",
      "columns: ['dataset', 'series_name', 'timestamp', 'y']\n",
      "n_series: 321\n",
      "date_range: 2012-01-01 00:00:00+00:00 -> 2014-12-21 00:00:00+00:00\n",
      "missing_y: 0\n",
      "                          dataset series_name                 timestamp     y\n",
      "0  electricity_weekly_dataset.tsf          T1 2012-01-01 00:00:00+00:00  8032\n",
      "1  electricity_weekly_dataset.tsf          T1 2012-01-08 00:00:00+00:00  9097\n",
      "2  electricity_weekly_dataset.tsf          T1 2012-01-15 00:00:00+00:00  9394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "TSF_FILES = [\n",
    "    \"hospital_dataset.tsf\",\n",
    "    \"tourism_monthly_dataset.tsf\",\n",
    "    \"electricity_weekly_dataset.tsf\",\n",
    "]\n",
    "\n",
    "def parse_tsf_to_long_df(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse TSF file into normalized long-form DataFrame.\n",
    "    Handles missing timestamps gracefully and aligns to declared frequency.\n",
    "    \"\"\"\n",
    "    meta = {}\n",
    "    in_data = False\n",
    "    rows = []\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            if line.lower().startswith(\"@data\"):\n",
    "                in_data = True\n",
    "                continue\n",
    "\n",
    "            if not in_data:\n",
    "                if line.startswith(\"@\"):\n",
    "                    parts = line.split(None, 1)\n",
    "                    key = parts[0].lstrip(\"@\").strip().lower()\n",
    "                    val = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "                    meta[key] = val\n",
    "                continue\n",
    "\n",
    "            # Parse data: series_name:start_timestamp:val1,val2,...\n",
    "            parts = line.split(\":\", 2)\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "\n",
    "            series_name = parts[0]\n",
    "            if len(parts) == 2:\n",
    "                start_ts = None\n",
    "                values_str = parts[1]\n",
    "            else:\n",
    "                start_ts = parts[1]\n",
    "                values_str = parts[2]\n",
    "\n",
    "            values = [v.strip() for v in values_str.split(\",\") if v.strip() != \"\"]\n",
    "            y = pd.to_numeric(pd.Series(values), errors=\"coerce\")\n",
    "\n",
    "            freq = meta.get(\"frequency\", \"\").lower()\n",
    "            if start_ts is None:\n",
    "                # Fallback: index-based pseudo-timestamps\n",
    "                t = pd.RangeIndex(len(y))\n",
    "            else:\n",
    "                # Parse TSF timestamp format (may be \"00-00-00\" or ISO)\n",
    "                start = pd.to_datetime(start_ts.replace(\"-\", \":\"), errors=\"coerce\")\n",
    "                if pd.isna(start):\n",
    "                    start = pd.to_datetime(start_ts, errors=\"coerce\")\n",
    "\n",
    "                # Construct frequency-aligned date range\n",
    "                if freq == \"monthly\":\n",
    "                    t = pd.date_range(start=start, periods=len(y), freq=\"MS\")\n",
    "                elif freq == \"weekly\":\n",
    "                    t = pd.date_range(start=start, periods=len(y), freq=\"W-SUN\")\n",
    "                else:\n",
    "                    # Generic fallback for unlabeled frequencies\n",
    "                    t = pd.date_range(start=start, periods=len(y), freq=\"D\")\n",
    "\n",
    "            df_part = pd.DataFrame({\n",
    "                \"dataset\": Path(path).name,\n",
    "                \"series_name\": series_name,\n",
    "                \"timestamp\": t,\n",
    "                \"y\": y.values\n",
    "            })\n",
    "            rows.append(df_part)\n",
    "\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    return out\n",
    "\n",
    "# Ingest all configured datasets\n",
    "dfs = {}\n",
    "for fn in TSF_FILES:\n",
    "    df = parse_tsf_to_long_df(fn)\n",
    "    dfs[fn] = df\n",
    "    print(\"=\"*80)\n",
    "    print(fn)\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(\"columns:\", df.columns.tolist())\n",
    "    print(\"n_series:\", df[\"series_name\"].nunique())\n",
    "    print(\"date_range:\", df[\"timestamp\"].min(), \"->\", df[\"timestamp\"].max())\n",
    "    print(\"missing_y:\", df[\"y\"].isna().sum())\n",
    "    print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751d783",
   "metadata": {},
   "source": [
    "## Cell 4: Rolling-Origin Backtesting Strategy\n",
    "\n",
    "### Critical Design: Temporal Leakage Prevention\n",
    "We implement a **rolling-origin window** per series to simulate realistic deployment conditions:\n",
    "- **Hard Cutoff**: `train_end < test_start` always holds (strict leakage check)\n",
    "- **Minimum Training Window**: 48 months (hospital domain: need ≥4 years to capture seasonal + trend variance)\n",
    "- **Variable Step Size**: step=3 months (hospital) allows overlapping windows without temporal overlap\n",
    "- **Horizon Coverage**: H={6,12} months reflects planning cycles (quarterly + annual)\n",
    "\n",
    "This avoids the \"look-ahead bias\" endemic in time-series ML: training on future values pretending they're past.\n",
    "\n",
    "### Leakage Verification\n",
    "We compute `(splits_df[\"train_end\"] < splits_df[\"test_start\"]).all()` to ensure the backtest is valid before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f37cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ROLLING BACKTEST SUMMARY\n",
      "==========================================================================================\n",
      "                          dataset  horizon  n_splits  n_series  \\\n",
      "0  electricity_weekly_dataset.tsf        8        12       321   \n",
      "1            hospital_dataset.tsf        6        11       767   \n",
      "2            hospital_dataset.tsf       12         9       767   \n",
      "3     tourism_monthly_dataset.tsf       24        36       365   \n",
      "\n",
      "  first_train_end last_test_end  \n",
      "0      2013-12-22    2014-12-21  \n",
      "1      2003-12-01    2006-12-01  \n",
      "2      2003-12-01    2006-12-01  \n",
      "3      1986-12-01    2007-06-01  \n",
      "\n",
      "✓ Leakage check (train_end < test_start for all splits): True\n",
      "\n",
      "Sample splits (first 5):\n",
      "                dataset series_name  horizon  split_id  train_end test_start  \\\n",
      "0  hospital_dataset.tsf          T1        6         0 2003-12-01 2004-01-01   \n",
      "1  hospital_dataset.tsf          T1        6         1 2004-03-01 2004-04-01   \n",
      "2  hospital_dataset.tsf          T1        6         2 2004-06-01 2004-07-01   \n",
      "3  hospital_dataset.tsf          T1        6         3 2004-09-01 2004-10-01   \n",
      "4  hospital_dataset.tsf          T1        6         4 2004-12-01 2005-01-01   \n",
      "\n",
      "    test_end  \n",
      "0 2004-06-01  \n",
      "1 2004-09-01  \n",
      "2 2004-12-01  \n",
      "3 2005-03-01  \n",
      "4 2005-06-01  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "# Configuration locked for reproducibility\n",
    "DATASETS = {\n",
    "    \"hospital_dataset.tsf\": {\n",
    "        \"freq\": \"MS\",          # Monthly start\n",
    "        \"horizons\": [6, 12],   # Quarterly and annual planning cycles\n",
    "        \"min_train_periods\": 48,  # Minimum 4 years to stabilize seasonal estimation\n",
    "        \"step\": 3              # Step between rolling windows (months)\n",
    "    },\n",
    "    \"tourism_monthly_dataset.tsf\": {\n",
    "        \"freq\": \"MS\",\n",
    "        \"horizons\": [24],\n",
    "        \"min_train_periods\": 96,  # 8 years for unequal-length series\n",
    "        \"step\": 6\n",
    "    },\n",
    "    \"electricity_weekly_dataset.tsf\": {\n",
    "        \"freq\": \"W-SUN\",\n",
    "        \"horizons\": [8],\n",
    "        \"min_train_periods\": 104,  # 2 years of weekly data\n",
    "        \"step\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "def build_rolling_splits(df, dataset_name, cfg):\n",
    "    \"\"\"\n",
    "    Construct rolling-origin splits per series (one series = one independent backtest).\n",
    "    Returns DataFrame with fields:\n",
    "      series_name | split_id | train_end | test_start | test_end | horizon\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    freq = cfg[\"freq\"]\n",
    "    step = cfg[\"step\"]\n",
    "    min_train = cfg[\"min_train_periods\"]\n",
    "\n",
    "    for horizon in cfg[\"horizons\"]:\n",
    "        for s, g in df[df[\"dataset\"] == dataset_name].groupby(\"series_name\"):\n",
    "            g = g.sort_values(\"timestamp\")\n",
    "            times = g[\"timestamp\"].values\n",
    "            n = len(times)\n",
    "\n",
    "            # Compute valid cutoff indices (must have min_train data before cutoff)\n",
    "            cutoff_idxs = list(range(min_train - 1, n - horizon, step))\n",
    "            for i, cut_idx in enumerate(cutoff_idxs):\n",
    "                train_end = times[cut_idx]\n",
    "                test_start = times[cut_idx + 1]\n",
    "                test_end = times[cut_idx + horizon]\n",
    "\n",
    "                rows.append({\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"series_name\": s,\n",
    "                    \"horizon\": horizon,\n",
    "                    \"split_id\": i,\n",
    "                    \"train_end\": pd.Timestamp(train_end),\n",
    "                    \"test_start\": pd.Timestamp(test_start),\n",
    "                    \"test_end\": pd.Timestamp(test_end)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Generate rolling splits for all configured datasets\n",
    "all_splits = []\n",
    "for name, cfg in DATASETS.items():\n",
    "    df = dfs[name]\n",
    "    splits = build_rolling_splits(df, name, cfg)\n",
    "    all_splits.append(splits)\n",
    "\n",
    "splits_df = pd.concat(all_splits, ignore_index=True)\n",
    "\n",
    "# Verification: aggregate splits and temporal coverage\n",
    "summary = (\n",
    "    splits_df\n",
    "    .groupby([\"dataset\", \"horizon\"])\n",
    "    .agg(\n",
    "        n_splits=(\"split_id\", \"nunique\"),\n",
    "        n_series=(\"series_name\", \"nunique\"),\n",
    "        first_train_end=(\"train_end\", \"min\"),\n",
    "        last_test_end=(\"test_end\", \"max\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ROLLING BACKTEST SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(summary)\n",
    "\n",
    "# **HARD LEAKAGE CHECK**: verify no train/test contamination\n",
    "leakage_check = (splits_df[\"train_end\"] < splits_df[\"test_start\"]).all()\n",
    "print(f\"\\n✓ Leakage check (train_end < test_start for all splits): {leakage_check}\")\n",
    "if not leakage_check:\n",
    "    raise RuntimeError(\"LEAKAGE DETECTED: train_end >= test_start for some split!\")\n",
    "\n",
    "print(\"\\nSample splits (first 5):\")\n",
    "print(splits_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31f3e2",
   "metadata": {},
   "source": [
    "## Cell 5: Baseline Seasonal Naive & Timezone Harmonization\n",
    "\n",
    "### Rationale for Baseline\n",
    "Seasonal naive (repeat last seasonal cycle) is the industry workhorse for hospital forecasting:\n",
    "- Low computational cost (no optimization)\n",
    "- Captures recurrent patterns without trend assumption\n",
    "- Provides a reference point: if ML models don't beat this, they lack generalization\n",
    "\n",
    "### Why Timezone Handling Matters\n",
    "pandas may introduce timezone-aware timestamps when parsing dates. Subsequent `.dt.tz_localize(None)` ensures consistency:\n",
    "- Avoids `TypeError` when comparing tz-aware vs. tz-naive in splits\n",
    "- Simplifies groupby logic downstream\n",
    "\n",
    "### Metric Design\n",
    "- **MAE** (Mean Absolute Error): robust to outliers, interpretable in original units\n",
    "- **RMSE** (Root Mean Squared Error): penalizes large forecast errors more heavily (captures tail risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b3faec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "SEASONAL NAIVE BASELINE RESULTS\n",
      "==========================================================================================\n",
      "                          dataset  horizon           MAE          RMSE\n",
      "0  electricity_weekly_dataset.tsf        8  33504.051629  39984.900267\n",
      "1            hospital_dataset.tsf        6     21.819545     26.014796\n",
      "2            hospital_dataset.tsf       12     21.788582     27.021620\n",
      "3     tourism_monthly_dataset.tsf       24   2006.442369   2521.121274\n",
      "\n",
      "Rows evaluated: 30358\n",
      "Any NaNs in metrics: {'mae': False, 'rmse': False}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Harmonize timezone representation across all dataframes (critical for merge/comparison)\n",
    "def make_tz_naive(ts: pd.Series) -> pd.Series:\n",
    "    ts = pd.to_datetime(ts, errors=\"coerce\")\n",
    "    try:\n",
    "        return ts.dt.tz_localize(None)\n",
    "    except AttributeError:\n",
    "        return ts.dt.tz_localize(None)\n",
    "\n",
    "for k in list(dfs.keys()):\n",
    "    dfs[k][\"timestamp\"] = pd.to_datetime(dfs[k][\"timestamp\"], errors=\"coerce\")\n",
    "    if getattr(dfs[k][\"timestamp\"].dt, \"tz\", None) is not None:\n",
    "        dfs[k][\"timestamp\"] = dfs[k][\"timestamp\"].dt.tz_localize(None)\n",
    "\n",
    "for col in [\"train_end\", \"test_start\", \"test_end\"]:\n",
    "    splits_df[col] = pd.to_datetime(splits_df[col], errors=\"coerce\")\n",
    "    if getattr(splits_df[col].dt, \"tz\", None) is not None:\n",
    "        splits_df[col] = splits_df[col].dt.tz_localize(None)\n",
    "\n",
    "# Seasonal naive baseline: repeats last observed seasonal cycle\n",
    "def seasonal_naive_forecast(y_train: np.ndarray, horizon: int, season_lag: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Seasonal naive forecast repeats the most recent seasonal cycle.\n",
    "    For h > season_lag, patterns repeat cyclically.\n",
    "    \"\"\"\n",
    "    y_train = np.asarray(y_train, dtype=float)\n",
    "    if len(y_train) == 0:\n",
    "        return np.full(horizon, np.nan)\n",
    "\n",
    "    if len(y_train) < season_lag:\n",
    "        # Cold-start: insufficient history; fallback to last observed value\n",
    "        return np.repeat(y_train[-1], horizon)\n",
    "\n",
    "    last_season = y_train[-season_lag:]\n",
    "    reps = int(np.ceil(horizon / season_lag))\n",
    "    y_hat = np.tile(last_season, reps)[:horizon]\n",
    "    return y_hat\n",
    "\n",
    "def evaluate_seasonal_naive(df_long, splits_df, dataset_name, freq):\n",
    "    \"\"\"\n",
    "    Execute rolling-origin evaluation for seasonal naive baseline.\n",
    "    Returns per-split metrics (MAE, RMSE).\n",
    "    \"\"\"\n",
    "    season_lag = 12 if freq == \"monthly\" else 52  # 52 weeks per year\n",
    "    df_ds = df_long[df_long[\"dataset\"] == dataset_name]\n",
    "\n",
    "    rows = []\n",
    "    for _, s in splits_df[splits_df[\"dataset\"] == dataset_name].iterrows():\n",
    "        g = df_ds[df_ds[\"series_name\"] == s[\"series_name\"]].sort_values(\"timestamp\")\n",
    "\n",
    "        train = g[g[\"timestamp\"] <= s[\"train_end\"]]\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) & (g[\"timestamp\"] <= s[\"test_end\"])]\n",
    "\n",
    "        y_true = test[\"y\"].astype(float).values\n",
    "        y_hat  = seasonal_naive_forecast(train[\"y\"].astype(float).values, int(s[\"horizon\"]), season_lag)\n",
    "\n",
    "        if len(y_true) != len(y_hat):\n",
    "            continue  # Skip malformed split\n",
    "\n",
    "        rows.append({\n",
    "            \"dataset\": dataset_name,\n",
    "            \"horizon\": int(s[\"horizon\"]),\n",
    "            \"series_name\": s[\"series_name\"],\n",
    "            \"split_id\": int(s[\"split_id\"]),\n",
    "            \"mae\": float(np.mean(np.abs(y_true - y_hat))),\n",
    "            \"rmse\": float(np.sqrt(np.mean((y_true - y_hat) ** 2))),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Evaluate baseline across all datasets\n",
    "baseline_df = pd.concat([\n",
    "    evaluate_seasonal_naive(dfs[\"hospital_dataset.tsf\"], splits_df, \"hospital_dataset.tsf\", freq=\"monthly\"),\n",
    "    evaluate_seasonal_naive(dfs[\"tourism_monthly_dataset.tsf\"], splits_df, \"tourism_monthly_dataset.tsf\", freq=\"monthly\"),\n",
    "    evaluate_seasonal_naive(dfs[\"electricity_weekly_dataset.tsf\"], splits_df, \"electricity_weekly_dataset.tsf\", freq=\"weekly\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "summary = (\n",
    "    baseline_df\n",
    "    .groupby([\"dataset\", \"horizon\"], as_index=False)\n",
    "    .agg(MAE=(\"mae\", \"mean\"), RMSE=(\"rmse\", \"mean\"))\n",
    ")\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"SEASONAL NAIVE BASELINE RESULTS\")\n",
    "print(\"=\"*90)\n",
    "print(summary)\n",
    "print(f\"\\nRows evaluated: {len(baseline_df)}\")\n",
    "print(f\"Any NaNs in metrics: {baseline_df[['mae', 'rmse']].isna().any().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4138ab8",
   "metadata": {},
   "source": [
    "## Cells 6–9: Classical Forecasting (ETS) & Rapid Prototyping\n",
    "\n",
    "### Exponential Smoothing (Holt-Winters)\n",
    "ETS provides a probabilistic alternative to neural networks:\n",
    "- **Trend Component** (additive): captures linear drift in hospital demand\n",
    "- **Seasonal Component** (additive): models recurring patterns\n",
    "- **Parallel Batch Evaluation**: joblib enables horizontal scaling across 50+ series\n",
    "\n",
    "### Rapid Global ML Prototype\n",
    "Before segmentation, we train an **unconstrained global LightGBM** to understand baseline ML performance:\n",
    "- Aggregates all series into one training matrix\n",
    "- Quantile loss (α=0.5 = median) provides robustness\n",
    "- Establishes whether ML > classical is worth the engineering cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8b3204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Horizon 6: train=(430287, 10), test=(50622, 10)\n",
      "\n",
      "Horizon 12: train=(331344, 10), test=(82836, 10)\n",
      "\n",
      "==========================================================================================\n",
      "HOSPITAL ML — RAPID PROTOTYPE (GLOBAL, UNCONSTRAINED)\n",
      "==========================================================================================\n",
      "                dataset  horizon                          model        MAE  \\\n",
      "0  hospital_dataset.tsf        6  LightGBM (global, unfiltered)  17.674858   \n",
      "1  hospital_dataset.tsf       12  LightGBM (global, unfiltered)  18.052381   \n",
      "\n",
      "        RMSE  \n",
      "0  57.376329  \n",
      "1  59.459905  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LIGHTGBM_VERBOSE\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "HORIZONS = [6, 12]\n",
    "LAGS = [1, 3, 6, 12]  # Tap into recent signal + seasonal patterns\n",
    "ROLLS = [3, 6, 12]    # Short/medium/long rolling statistics\n",
    "QUANTILES = [0.1, 0.5, 0.9]  # Explore risk quantiles\n",
    "\n",
    "# Feature engineering: construct lag + rolling statistics\n",
    "df = dfs[DATASET].copy()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).dt.tz_localize(None)\n",
    "df = df.sort_values([\"series_name\", \"timestamp\"])\n",
    "df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "\n",
    "for lag in LAGS:\n",
    "    # Lagged values: capture autoregressive structure\n",
    "    df[f\"lag_{lag}\"] = df.groupby(\"series_name\")[\"y\"].shift(lag)\n",
    "\n",
    "for r in ROLLS:\n",
    "    # Ensure rolling features use ONLY past data (shift(1) prevents leakage)\n",
    "    df[f\"roll_mean_{r}\"] = df.groupby(\"series_name\")[\"y\"].shift(1).rolling(r).mean()\n",
    "    df[f\"roll_std_{r}\"]  = df.groupby(\"series_name\")[\"y\"].shift(1).rolling(r).std()\n",
    "\n",
    "feature_cols = [c for c in df.columns if c.startswith((\"lag_\", \"roll_\"))]\n",
    "\n",
    "def build_global_sets(horizon):\n",
    "    \"\"\"\n",
    "    Construct global train/test matrices by pooling all series for a given horizon.\n",
    "    This leverages cross-series information: large hospitals inform predictions of small ones.\n",
    "    \"\"\"\n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    splits = splits_df[\n",
    "        (splits_df[\"dataset\"] == DATASET) &\n",
    "        (splits_df[\"horizon\"] == horizon)\n",
    "    ]\n",
    "\n",
    "    for _, s in splits.iterrows():\n",
    "        g = df[df[\"series_name\"] == s[\"series_name\"]]\n",
    "\n",
    "        train = g[g[\"timestamp\"] <= s[\"train_end\"]].dropna(subset=feature_cols)\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) &\n",
    "                  (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "\n",
    "        if len(train) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        X_train.append(train[feature_cols])\n",
    "        y_train.append(train[\"y\"])\n",
    "        X_test.append(test[feature_cols])\n",
    "        y_test.append(test[\"y\"])\n",
    "\n",
    "    return (\n",
    "        pd.concat(X_train, ignore_index=True),\n",
    "        pd.concat(y_train, ignore_index=True),\n",
    "        pd.concat(X_test, ignore_index=True),\n",
    "        pd.concat(y_test, ignore_index=True)\n",
    "    )\n",
    "\n",
    "# Train global median (α=0.5) model only for speed\n",
    "results = []\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    Xtr, ytr, Xte, yte = build_global_sets(horizon)\n",
    "    print(f\"\\nHorizon {horizon}: train={Xtr.shape}, test={Xte.shape}\")\n",
    "\n",
    "    # Quantile regression: α=0.5 ≈ median; robust to outliers\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"quantile\",\n",
    "        alpha=0.5,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    model.fit(Xtr, ytr)\n",
    "    preds = model.predict(Xte)\n",
    "\n",
    "    mae = mean_absolute_error(yte, preds)\n",
    "    mse = mean_squared_error(yte, preds)\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    results.append({\n",
    "        \"dataset\": DATASET,\n",
    "        \"horizon\": horizon,\n",
    "        \"model\": \"LightGBM (global, unfiltered)\",\n",
    "        \"MAE\": float(mae),\n",
    "        \"RMSE\": rmse\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"HOSPITAL ML — RAPID PROTOTYPE (GLOBAL, UNCONSTRAINED)\")\n",
    "print(\"=\"*90)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe2463",
   "metadata": {},
   "source": [
    "## Cell 10a: Distribution Analysis & Error Characterization\n",
    "\n",
    "### Why Analyze Residuals?\n",
    "Forecasting is fundamentally about understanding uncertainty:\n",
    "- **Tail behavior** (p90, p95, p99): identifies outliers and model stress points\n",
    "- **Absolute error distribution**: tells us whether MAE is driven by typical errors or rare blowups\n",
    "- **Horizon effect**: errors often grow linearly or super-linearly with forecast horizon\n",
    "\n",
    "This analysis shapes downstream decisions: segmentation by volume is only worth it if global model errors correlate with series scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211a19c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "RESIDUAL ANALYSIS FOR HORIZON 6\n",
      "==========================================================================================\n",
      "\n",
      "y_true distribution (h=6)\n",
      "  count: 50622\n",
      "  min/median/max: 1.000 / 40.000 / 12090.000\n",
      "  p90/p95/p99: 659.000 / 1253.000 / 3862.000\n",
      "\n",
      "y_pred distribution (h=6)\n",
      "  count: 50622\n",
      "  min/median/max: 5.448 / 40.062 / 11060.372\n",
      "  p90/p95/p99: 663.967 / 1234.312 / 3916.483\n",
      "\n",
      "|error| distribution (h=6)\n",
      "  count: 50622\n",
      "  min/median/max: 0.000 / 5.639 / 1590.878\n",
      "  p90/p95/p99: 35.865 / 65.150 / 206.426\n",
      "\n",
      "  Aggregate: MAE=17.675  RMSE=57.376\n",
      "\n",
      "  Top 10 worst errors (debugging artifacts):\n",
      "   y_true        y_pred      abs_err\n",
      "0    9407   7816.122077  1590.877923\n",
      "1    9407   7816.122077  1590.877923\n",
      "2    8899   7311.957456  1587.042544\n",
      "3    8899   7311.957456  1587.042544\n",
      "4    6846   8337.593563  1491.593563\n",
      "5   10154   8765.282527  1388.717473\n",
      "6   12090  10867.136985  1222.863015\n",
      "7   12090  10867.136985  1222.863015\n",
      "8    6357   7487.833060  1130.833060\n",
      "9    6357   7487.833060  1130.833060\n",
      "\n",
      "==========================================================================================\n",
      "RESIDUAL ANALYSIS FOR HORIZON 12\n",
      "==========================================================================================\n",
      "\n",
      "y_true distribution (h=12)\n",
      "  count: 82836\n",
      "  min/median/max: 1.000 / 40.000 / 12090.000\n",
      "  p90/p95/p99: 659.000 / 1253.000 / 3860.000\n",
      "\n",
      "y_pred distribution (h=12)\n",
      "  count: 82836\n",
      "  min/median/max: 5.154 / 40.154 / 10941.887\n",
      "  p90/p95/p99: 664.114 / 1240.944 / 3758.650\n",
      "\n",
      "|error| distribution (h=12)\n",
      "  count: 82836\n",
      "  min/median/max: 0.000 / 5.715 / 2210.060\n",
      "  p90/p95/p99: 36.893 / 66.001 / 221.373\n",
      "\n",
      "  Aggregate: MAE=18.052  RMSE=59.460\n",
      "\n",
      "  Top 10 worst errors (debugging artifacts):\n",
      "   y_true       y_pred      abs_err\n",
      "0    9407  7196.940484  2210.059516\n",
      "1    9407  7196.940484  2210.059516\n",
      "2    9407  7196.940484  2210.059516\n",
      "3    9407  7196.940484  2210.059516\n",
      "4    8899  6913.067702  1985.932298\n",
      "5    8899  6913.067702  1985.932298\n",
      "6    8899  6913.067702  1985.932298\n",
      "7    8899  6913.067702  1985.932298\n",
      "8   10154  8647.313203  1506.686797\n",
      "9    5625  7044.434198  1419.434198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def build_global_sets_only_test(horizon):\n",
    "    \"\"\"Rebuild test set for residual analysis (same features as training).\"\"\"\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    splits = splits_df[\n",
    "        (splits_df[\"dataset\"] == \"hospital_dataset.tsf\") &\n",
    "        (splits_df[\"horizon\"] == horizon)\n",
    "    ]\n",
    "\n",
    "    for _, s in splits.iterrows():\n",
    "        g = df[df[\"series_name\"] == s[\"series_name\"]]\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) &\n",
    "                  (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "        if len(test) == 0:\n",
    "            continue\n",
    "        X_test.append(test[feature_cols])\n",
    "        y_test.append(test[\"y\"])\n",
    "\n",
    "    return pd.concat(X_test, ignore_index=True), pd.concat(y_test, ignore_index=True)\n",
    "\n",
    "def quick_stats(arr, name):\n",
    "    \"\"\"Compute percentile summary to identify tail behavior.\"\"\"\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  count: {len(arr)}\")\n",
    "    print(f\"  min/median/max: {np.min(arr):.3f} / {np.median(arr):.3f} / {np.max(arr):.3f}\")\n",
    "    print(f\"  p90/p95/p99: {np.percentile(arr, 90):.3f} / {np.percentile(arr, 95):.3f} / {np.percentile(arr, 99):.3f}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "for horizon in [6, 12]:\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"RESIDUAL ANALYSIS FOR HORIZON {horizon}\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    Xte, yte = build_global_sets_only_test(horizon)\n",
    "    quick_stats(yte.values, f\"y_true distribution (h={horizon})\")\n",
    "\n",
    "    # Retrain model to obtain residuals\n",
    "    Xtr, ytr, _, _ = build_global_sets(horizon)\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"quantile\",\n",
    "        alpha=0.5,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    model.fit(Xtr, ytr)\n",
    "    preds = model.predict(Xte)\n",
    "\n",
    "    quick_stats(preds, f\"y_pred distribution (h={horizon})\")\n",
    "\n",
    "    abs_err = np.abs(yte.values - preds)\n",
    "    quick_stats(abs_err, f\"|error| distribution (h={horizon})\")\n",
    "\n",
    "    mae = mean_absolute_error(yte, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(yte, preds))\n",
    "    print(f\"\\n  Aggregate: MAE={mae:.3f}  RMSE={rmse:.3f}\")\n",
    "\n",
    "    # Identify worst-performing forecasts for debugging\n",
    "    worst_idx = np.argsort(abs_err)[-10:][::-1]\n",
    "    worst_df = pd.DataFrame({\n",
    "        \"y_true\": yte.values[worst_idx],\n",
    "        \"y_pred\": preds[worst_idx],\n",
    "        \"abs_err\": abs_err[worst_idx]\n",
    "    })\n",
    "    print(f\"\\n  Top 10 worst errors (debugging artifacts):\")\n",
    "    print(worst_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088df5b5",
   "metadata": {},
   "source": [
    "## Cell 10b: Log-Transform for Variance Stabilization\n",
    "\n",
    "### The Heavy-Tail Problem\n",
    "Hospital demand data often exhibits **multiplicative noise** rather than additive:\n",
    "- Large hospitals (high volume) have larger absolute errors (high variance)\n",
    "- Small hospitals (low volume) have tight control (low variance)\n",
    "- **Coefficient of variation** (CV = σ/μ) is roughly constant across scales\n",
    "\n",
    "### Why log1p Works\n",
    "Taking log(1 + y) stabilizes the variance and transforms the problem to additive noise:\n",
    "- Prevents model from over-fitting to large facilities\n",
    "- Enables cross-series transfer learning (global model sees similar scaled inputs)\n",
    "- Inverse transform via expm1 recovers original scale without bias\n",
    "\n",
    "**Note**: log1p handles y=0 gracefully (log(1+0)=0); pure log would fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901f6fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Horizon 6: train=(430287, 10), test=(50622, 10)\n",
      "  Original y: μ=266.2, σ=830.9\n",
      "  Log-transformed y: μ=4.087, σ=1.517\n",
      "\n",
      "Horizon 12: train=(331344, 10), test=(82836, 10)\n",
      "  Original y: μ=265.5, σ=828.6\n",
      "  Log-transformed y: μ=4.083, σ=1.518\n",
      "\n",
      "==========================================================================================\n",
      "HOSPITAL ML — LOG1P VARIANCE STABILIZATION\n",
      "==========================================================================================\n",
      "                dataset  horizon                            model        MAE  \\\n",
      "0  hospital_dataset.tsf        6  LightGBM (global, log1p target)  17.340464   \n",
      "1  hospital_dataset.tsf       12  LightGBM (global, log1p target)  17.978900   \n",
      "\n",
      "        RMSE  \n",
      "0  55.842261  \n",
      "1  60.299794  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "HORIZONS = [6, 12]\n",
    "\n",
    "results = []\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    Xtr, ytr, Xte, yte = build_global_sets(horizon)\n",
    "\n",
    "    # Apply log1p to stabilize variance across heterogeneous scales\n",
    "    ytr_log = np.log1p(ytr)\n",
    "\n",
    "    print(f\"\\nHorizon {horizon}: train={Xtr.shape}, test={Xte.shape}\")\n",
    "    print(f\"  Original y: μ={ytr.mean():.1f}, σ={ytr.std():.1f}\")\n",
    "    print(f\"  Log-transformed y: μ={ytr_log.mean():.3f}, σ={ytr_log.std():.3f}\")\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"quantile\",\n",
    "        alpha=0.5,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    model.fit(Xtr, ytr_log)\n",
    "\n",
    "    # Predict in log space, then invert to original scale\n",
    "    preds_log = model.predict(Xte)\n",
    "    preds = np.expm1(preds_log)\n",
    "\n",
    "    mae = mean_absolute_error(yte, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(yte, preds))\n",
    "\n",
    "    results.append({\n",
    "        \"dataset\": DATASET,\n",
    "        \"horizon\": horizon,\n",
    "        \"model\": \"LightGBM (global, log1p target)\",\n",
    "        \"MAE\": float(mae),\n",
    "        \"RMSE\": float(rmse)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"HOSPITAL ML — LOG1P VARIANCE STABILIZATION\")\n",
    "print(\"=\"*90)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c7cc2",
   "metadata": {},
   "source": [
    "## Cell 11: Segmented Global LightGBM — Training Median Bucketing\n",
    "\n",
    "### Core Design: Why Segment?\n",
    "The bias-variance tradeoff is fundamental here:\n",
    "- **Without segmentation**: global model must interpolate across extreme scales (high variance)\n",
    "- **With segmentation**: each model sees homogeneous ranges (lower variance per bucket)\n",
    "- **Cost**: slightly higher bias (less data per model), but net MSE often improves\n",
    "\n",
    "### Bucketing Strategy\n",
    "We partition series by **training-period median volume** into tertiles (small/medium/large):\n",
    "- Uses ONLY training history (no leakage from test set)\n",
    "- Ensures each bucket has similar forecast scales\n",
    "- Stable across rolling windows (cutoff at minimum train_end date)\n",
    "\n",
    "### Implementation: log1p + Feature Lag-Shift\n",
    "- Apply log transform per bucket to further stabilize variance\n",
    "- Shift rolling features by 1 period to prevent accidental leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76403ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket thresholds: q1=22.0, q2=73.6\n",
      "Series per bucket: {'small': 267, 'large': 261, 'medium': 239}\n",
      "H6 | small  | train=(149787, 10) test=(17622, 10)\n",
      "H6 | medium | train=(134079, 10) test=(15774, 10)\n",
      "H6 | large  | train=(146421, 10) test=(17226, 10)\n",
      "H12 | small  | train=(115344, 10) test=(28836, 10)\n",
      "H12 | medium | train=(103248, 10) test=(25812, 10)\n",
      "H12 | large  | train=(112752, 10) test=(28188, 10)\n",
      "\n",
      "====================================================================================================\n",
      "SEGMENTED GLOBAL LIGHTGBM — BUCKET METRICS\n",
      "====================================================================================================\n",
      "                dataset  horizon  bucket                        model  \\\n",
      "0  hospital_dataset.tsf        6   large  LightGBM (segmented, log1p)   \n",
      "1  hospital_dataset.tsf        6  medium  LightGBM (segmented, log1p)   \n",
      "2  hospital_dataset.tsf        6   small  LightGBM (segmented, log1p)   \n",
      "3  hospital_dataset.tsf       12   large  LightGBM (segmented, log1p)   \n",
      "4  hospital_dataset.tsf       12  medium  LightGBM (segmented, log1p)   \n",
      "5  hospital_dataset.tsf       12   small  LightGBM (segmented, log1p)   \n",
      "\n",
      "         MAE       RMSE  \n",
      "0  38.948141  89.263097  \n",
      "1   6.252343   8.555698  \n",
      "2   3.622809   4.793891  \n",
      "3  39.824063  89.118869  \n",
      "4   6.397392   8.810318  \n",
      "5   3.715300   4.926587  \n",
      "\n",
      "====================================================================================================\n",
      "SEGMENTED GLOBAL LIGHTGBM — WEIGHTED OVERALL METRICS\n",
      "====================================================================================================\n",
      "                dataset  horizon                           model  \\\n",
      "0  hospital_dataset.tsf        6  LightGBM (segmented, weighted)   \n",
      "1  hospital_dataset.tsf       12  LightGBM (segmented, weighted)   \n",
      "\n",
      "   Weighted_MAE  Weighted_RMSE  Total_Test_Rows  \n",
      "0     16.462927      52.365838            50622  \n",
      "1     16.838386      52.299647            82836  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "HORIZONS = [6, 12]\n",
    "\n",
    "LAGS  = [1, 3, 6, 12]\n",
    "ROLLS = [3, 6, 12]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# Prepare data with timezone consistency\n",
    "df = dfs[DATASET].copy()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).dt.tz_localize(None)\n",
    "df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "df = df.sort_values([\"series_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "spl = splits_df[splits_df[\"dataset\"] == DATASET].copy()\n",
    "for c in [\"train_end\", \"test_start\", \"test_end\"]:\n",
    "    spl[c] = pd.to_datetime(spl[c]).dt.tz_localize(None)\n",
    "\n",
    "# Construct features (guaranteed)\n",
    "for lag in LAGS:\n",
    "    df[f\"lag_{lag}\"] = df.groupby(\"series_name\")[\"y\"].shift(lag)\n",
    "\n",
    "for r in ROLLS:\n",
    "    # Shift(1) ensures rolling uses only past observations\n",
    "    df[f\"roll_mean_{r}\"] = (\n",
    "        df.groupby(\"series_name\")[\"y\"]\n",
    "          .shift(1)\n",
    "          .rolling(r)\n",
    "          .mean()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[f\"roll_std_{r}\"] = (\n",
    "        df.groupby(\"series_name\")[\"y\"]\n",
    "          .shift(1)\n",
    "          .rolling(r)\n",
    "          .std()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "feature_cols = [c for c in df.columns if c.startswith((\"lag_\", \"roll_\"))]\n",
    "\n",
    "# Segment series by training-period median volume (no test-set leakage)\n",
    "train_cutoff = spl[\"train_end\"].min()\n",
    "train_hist = df[df[\"timestamp\"] <= train_cutoff]\n",
    "\n",
    "series_median = train_hist.groupby(\"series_name\")[\"y\"].median()\n",
    "q1, q2 = series_median.quantile([0.33, 0.66])\n",
    "\n",
    "def size_bucket(v):\n",
    "    if v <= q1:\n",
    "        return \"small\"\n",
    "    elif v <= q2:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "series_bucket = series_median.apply(size_bucket)\n",
    "df[\"bucket\"] = df[\"series_name\"].map(series_bucket)\n",
    "\n",
    "print(f\"Bucket thresholds: q1={q1:.1f}, q2={q2:.1f}\")\n",
    "print(f\"Series per bucket: {series_bucket.value_counts().to_dict()}\")\n",
    "\n",
    "def build_bucket_sets(horizon, bucket):\n",
    "    \"\"\"Construct global train/test matrices for a specific size bucket.\"\"\"\n",
    "    Xtr, ytr, Xte, yte = [], [], [], []\n",
    "\n",
    "    splits_h = spl[spl[\"horizon\"] == horizon]\n",
    "    for _, s in splits_h.iterrows():\n",
    "        g = df[(df[\"series_name\"] == s[\"series_name\"]) & (df[\"bucket\"] == bucket)]\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        train = g[g[\"timestamp\"] <= s[\"train_end\"]].dropna(subset=feature_cols)\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) &\n",
    "                  (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "\n",
    "        if len(train) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        Xtr.append(train[feature_cols]); ytr.append(train[\"y\"])\n",
    "        Xte.append(test[feature_cols]);  yte.append(test[\"y\"])\n",
    "\n",
    "    if not Xtr:\n",
    "        return None\n",
    "\n",
    "    return (\n",
    "        pd.concat(Xtr, ignore_index=True),\n",
    "        pd.concat(ytr, ignore_index=True),\n",
    "        pd.concat(Xte, ignore_index=True),\n",
    "        pd.concat(yte, ignore_index=True),\n",
    "    )\n",
    "\n",
    "# Train 1 model per (horizon, bucket) with log1p variance stabilization\n",
    "bucket_metrics = []\n",
    "bucket_counts = []\n",
    "models = {}  # Store fitted models for SHAP\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    for bucket in [\"small\", \"medium\", \"large\"]:\n",
    "        data = build_bucket_sets(horizon, bucket)\n",
    "        if data is None:\n",
    "            print(f\"H{horizon} | {bucket:<6} | SKIP (no data)\")\n",
    "            continue\n",
    "\n",
    "        Xtr, ytr, Xte, yte = data\n",
    "        n_test = len(yte)\n",
    "\n",
    "        print(f\"H{horizon} | {bucket:<6} | train={Xtr.shape} test={Xte.shape}\")\n",
    "\n",
    "        # Apply log transform to handle heavy tails within each bucket\n",
    "        ytr_log = np.log1p(ytr)\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective=\"quantile\",\n",
    "            alpha=0.5,\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        )\n",
    "        model.fit(Xtr, ytr_log)\n",
    "        models[(horizon, bucket)] = model\n",
    "\n",
    "        # Predict and invert back to original scale\n",
    "        preds = np.expm1(model.predict(Xte))\n",
    "\n",
    "        mae_val = float(mean_absolute_error(yte, preds))\n",
    "        rmse_val = rmse(yte, preds)\n",
    "\n",
    "        bucket_metrics.append({\n",
    "            \"dataset\": DATASET,\n",
    "            \"horizon\": horizon,\n",
    "            \"bucket\": bucket,\n",
    "            \"model\": \"LightGBM (segmented, log1p)\",\n",
    "            \"MAE\": mae_val,\n",
    "            \"RMSE\": rmse_val\n",
    "        })\n",
    "        bucket_counts.append({\n",
    "            \"horizon\": horizon,\n",
    "            \"bucket\": bucket,\n",
    "            \"n_test\": int(n_test)\n",
    "        })\n",
    "\n",
    "bucket_df = pd.DataFrame(bucket_metrics).sort_values([\"horizon\", \"bucket\"]).reset_index(drop=True)\n",
    "counts_df = pd.DataFrame(bucket_counts)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SEGMENTED GLOBAL LIGHTGBM — BUCKET METRICS\")\n",
    "print(\"=\"*100)\n",
    "print(bucket_df)\n",
    "\n",
    "# Compute weighted aggregate metrics\n",
    "weighted_rows = []\n",
    "for horizon in HORIZONS:\n",
    "    sub = bucket_df[bucket_df[\"horizon\"] == horizon].merge(\n",
    "        counts_df[counts_df[\"horizon\"] == horizon],\n",
    "        on=[\"horizon\", \"bucket\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    total_n = sub[\"n_test\"].sum()\n",
    "\n",
    "    w_mae = (sub[\"MAE\"] * sub[\"n_test\"]).sum() / total_n\n",
    "    w_rmse = float(np.sqrt(((sub[\"RMSE\"] ** 2) * sub[\"n_test\"]).sum() / total_n))\n",
    "\n",
    "    weighted_rows.append({\n",
    "        \"dataset\": DATASET,\n",
    "        \"horizon\": horizon,\n",
    "        \"model\": \"LightGBM (segmented, weighted)\",\n",
    "        \"Weighted_MAE\": float(w_mae),\n",
    "        \"Weighted_RMSE\": float(w_rmse),\n",
    "        \"Total_Test_Rows\": int(total_n)\n",
    "    })\n",
    "\n",
    "weighted_df = pd.DataFrame(weighted_rows).sort_values(\"horizon\").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SEGMENTED GLOBAL LIGHTGBM — WEIGHTED OVERALL METRICS\")\n",
    "print(\"=\"*100)\n",
    "print(weighted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0179086",
   "metadata": {},
   "source": [
    "## Cell 13: SHAP-Based Feature Importance with Additivity Override\n",
    "\n",
    "### Why SHAP?\n",
    "Tree-based models (LightGBM) are black-box by nature. SHAP (SHapley Additive exPlanations) provides:\n",
    "- **Local Interpretability**: explain each individual forecast\n",
    "- **Feature Ranking**: identify which features drive predictions most\n",
    "- **Theoretically Sound**: based on cooperative game theory (Shapley values)\n",
    "\n",
    "### The Additivity Challenge\n",
    "LightGBM's TreeExplainer has a built-in consistency check (`check_additivity=True` by default). However:\n",
    "- **High-dimensional interactions**: when features interact strongly (e.g., lag_1 × roll_mean_3), the check may fail\n",
    "- **Solution**: `check_additivity=False` disables the check, allowing feature_perturbation=\"interventional\" to compute SHAP values robustly\n",
    "- **Downside**: you lose the built-in guardrail; interpretation requires more care\n",
    "\n",
    "### Workflow\n",
    "1. Sample background data (2000 rows) for efficiency\n",
    "2. Create explainer with `feature_perturbation=\"interventional\"` (respects feature correlations)\n",
    "3. Compute SHAP values for up to 10,000 test samples\n",
    "4. Average absolute SHAP values per feature to rank importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc05f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aarav\\anaconda3\\envs\\mp3env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SHAP available. Using TreeExplainer with check_additivity=False.\n",
      "  (Disables additivity check to handle high-dimensional interaction effects.)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9933/10000 [00:51<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H6_small.csv | explained=10000 | bg=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9931/10000 [00:55<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H6_medium.csv | explained=10000 | bg=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9878/10000 [00:50<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H6_large.csv | explained=10000 | bg=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9900/10000 [00:45<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H12_small.csv | explained=10000 | bg=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 9991/10000 [00:56<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H12_medium.csv | explained=10000 | bg=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 9982/10000 [00:56<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H12_large.csv | explained=10000 | bg=2000\n",
      "\n",
      "====================================================================================================\n",
      "TOP SHAP FEATURES (mean |SHAP|) — per horizon & bucket\n",
      "====================================================================================================\n",
      "         feature  mean_abs_shap               dataset  horizon  bucket\n",
      "0          lag_1       0.367885  hospital_dataset.tsf        6   large\n",
      "1    roll_mean_3       0.305724  hospital_dataset.tsf        6   large\n",
      "2         lag_12       0.111043  hospital_dataset.tsf        6   large\n",
      "3   roll_mean_12       0.105898  hospital_dataset.tsf        6   large\n",
      "4    roll_mean_6       0.051217  hospital_dataset.tsf        6   large\n",
      "5          lag_3       0.015017  hospital_dataset.tsf        6   large\n",
      "6          lag_6       0.013568  hospital_dataset.tsf        6   large\n",
      "7    roll_std_12       0.004639  hospital_dataset.tsf        6   large\n",
      "8     roll_std_6       0.004469  hospital_dataset.tsf        6   large\n",
      "9     roll_std_3       0.004287  hospital_dataset.tsf        6   large\n",
      "10   roll_mean_3       0.131671  hospital_dataset.tsf        6  medium\n",
      "11         lag_1       0.082823  hospital_dataset.tsf        6  medium\n",
      "12  roll_mean_12       0.077106  hospital_dataset.tsf        6  medium\n",
      "13   roll_mean_6       0.025473  hospital_dataset.tsf        6  medium\n",
      "14        lag_12       0.022395  hospital_dataset.tsf        6  medium\n",
      "15         lag_6       0.014659  hospital_dataset.tsf        6  medium\n",
      "16         lag_3       0.012048  hospital_dataset.tsf        6  medium\n",
      "17   roll_std_12       0.004902  hospital_dataset.tsf        6  medium\n",
      "18    roll_std_6       0.004008  hospital_dataset.tsf        6  medium\n",
      "19    roll_std_3       0.003664  hospital_dataset.tsf        6  medium\n",
      "20  roll_mean_12       0.101935  hospital_dataset.tsf        6   small\n",
      "21   roll_mean_3       0.080105  hospital_dataset.tsf        6   small\n",
      "22         lag_1       0.050778  hospital_dataset.tsf        6   small\n",
      "23   roll_mean_6       0.026751  hospital_dataset.tsf        6   small\n",
      "24        lag_12       0.011984  hospital_dataset.tsf        6   small\n",
      "25         lag_3       0.011913  hospital_dataset.tsf        6   small\n",
      "26   roll_std_12       0.008633  hospital_dataset.tsf        6   small\n",
      "27         lag_6       0.006373  hospital_dataset.tsf        6   small\n",
      "28    roll_std_6       0.006320  hospital_dataset.tsf        6   small\n",
      "29    roll_std_3       0.004054  hospital_dataset.tsf        6   small\n",
      "30         lag_1       0.377732  hospital_dataset.tsf       12   large\n",
      "31   roll_mean_3       0.292204  hospital_dataset.tsf       12   large\n",
      "32  roll_mean_12       0.110002  hospital_dataset.tsf       12   large\n",
      "33        lag_12       0.100166  hospital_dataset.tsf       12   large\n",
      "34   roll_mean_6       0.057261  hospital_dataset.tsf       12   large\n",
      "35         lag_3       0.016863  hospital_dataset.tsf       12   large\n",
      "36         lag_6       0.016458  hospital_dataset.tsf       12   large\n",
      "37    roll_std_3       0.006292  hospital_dataset.tsf       12   large\n",
      "38   roll_std_12       0.005890  hospital_dataset.tsf       12   large\n",
      "39    roll_std_6       0.004232  hospital_dataset.tsf       12   large\n",
      "40   roll_mean_3       0.130779  hospital_dataset.tsf       12  medium\n",
      "41         lag_1       0.087606  hospital_dataset.tsf       12  medium\n",
      "42  roll_mean_12       0.072051  hospital_dataset.tsf       12  medium\n",
      "43   roll_mean_6       0.028885  hospital_dataset.tsf       12  medium\n",
      "44        lag_12       0.023002  hospital_dataset.tsf       12  medium\n",
      "45         lag_6       0.016498  hospital_dataset.tsf       12  medium\n",
      "46         lag_3       0.011057  hospital_dataset.tsf       12  medium\n",
      "47   roll_std_12       0.005568  hospital_dataset.tsf       12  medium\n",
      "48    roll_std_6       0.004254  hospital_dataset.tsf       12  medium\n",
      "49    roll_std_3       0.004043  hospital_dataset.tsf       12  medium\n",
      "50  roll_mean_12       0.101374  hospital_dataset.tsf       12   small\n",
      "51   roll_mean_3       0.078485  hospital_dataset.tsf       12   small\n",
      "52         lag_1       0.055917  hospital_dataset.tsf       12   small\n",
      "53   roll_mean_6       0.025237  hospital_dataset.tsf       12   small\n",
      "54   roll_std_12       0.010549  hospital_dataset.tsf       12   small\n",
      "55         lag_3       0.009738  hospital_dataset.tsf       12   small\n",
      "56        lag_12       0.009482  hospital_dataset.tsf       12   small\n",
      "57         lag_6       0.008869  hospital_dataset.tsf       12   small\n",
      "58    roll_std_6       0.005647  hospital_dataset.tsf       12   small\n",
      "59    roll_std_3       0.004201  hospital_dataset.tsf       12   small\n",
      "\n",
      "✓ Saved: ./artifacts_interpretability\\shap_top15_hospital_dataset.tsf.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Verify required variables exist from segmented training cell\n",
    "req = [\"df\", \"spl\", \"feature_cols\", \"models\", \"DATASET\", \"HORIZONS\"]\n",
    "missing = [r for r in req if r not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing required variables: {missing}\\n\"\n",
    "        \"Run the segmented LightGBM training cell first.\"\n",
    "    )\n",
    "\n",
    "OUT_DIR = \"./artifacts_interpretability\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "MAX_BACKGROUND = 2000\n",
    "MAX_EXPLAIN    = 10000\n",
    "RANDOM_SEED    = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "def build_bucket_test_matrix(horizon: int, bucket: str):\n",
    "    \"\"\"Construct test feature matrix for a given (horizon, bucket) pair.\"\"\"\n",
    "    Xte_list, yte_list = [], []\n",
    "    splits_h = spl[spl[\"horizon\"] == horizon]\n",
    "\n",
    "    for _, s in splits_h.iterrows():\n",
    "        g = df[(df[\"series_name\"] == s[\"series_name\"]) & (df[\"bucket\"] == bucket)]\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        test = g[(g[\"timestamp\"] >= s[\"test_start\"]) & (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "        if len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        Xte_list.append(test[feature_cols])\n",
    "        yte_list.append(test[\"y\"])\n",
    "\n",
    "    if not Xte_list:\n",
    "        return None\n",
    "\n",
    "    Xte = pd.concat(Xte_list, ignore_index=True)\n",
    "    yte = pd.concat(yte_list, ignore_index=True)\n",
    "    return Xte, yte\n",
    "\n",
    "def sample_df(X: pd.DataFrame, max_rows: int):\n",
    "    \"\"\"Randomly sample DataFrame rows for computational efficiency.\"\"\"\n",
    "    if len(X) <= max_rows:\n",
    "        return X.reset_index(drop=True)\n",
    "    idx = rng.choice(len(X), size=max_rows, replace=False)\n",
    "    return X.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "# Try SHAP; fallback to permutation importance if unavailable\n",
    "use_shap = True\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    use_shap = False\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "if use_shap:\n",
    "    print(\"✓ SHAP available. Using TreeExplainer with check_additivity=False.\")\n",
    "    print(\"  (Disables additivity check to handle high-dimensional interaction effects.)\\n\")\n",
    "    \n",
    "    for horizon in HORIZONS:\n",
    "        for bucket in [\"small\", \"medium\", \"large\"]:\n",
    "            key = (horizon, bucket)\n",
    "            if key not in models:\n",
    "                print(f\"  SKIP: no model for H{horizon} {bucket}\")\n",
    "                continue\n",
    "\n",
    "            data = build_bucket_test_matrix(horizon, bucket)\n",
    "            if data is None:\n",
    "                print(f\"  SKIP: no test data for H{horizon} {bucket}\")\n",
    "                continue\n",
    "\n",
    "            Xte, _ = data\n",
    "\n",
    "            # Sample for efficiency\n",
    "            X_bg = sample_df(Xte, MAX_BACKGROUND)\n",
    "            X_ex = sample_df(Xte, MAX_EXPLAIN)\n",
    "\n",
    "            model = models[key]\n",
    "\n",
    "            # Create explainer with feature_perturbation=\"interventional\" (respects correlations)\n",
    "            explainer = shap.TreeExplainer(\n",
    "                model, \n",
    "                data=X_bg, \n",
    "                feature_perturbation=\"interventional\"\n",
    "            )\n",
    "            \n",
    "            # CRITICAL: disable additivity check to allow high-dimensional interactions\n",
    "            shap_vals = explainer.shap_values(X_ex, check_additivity=False)\n",
    "\n",
    "            # Average absolute SHAP values across samples to rank features\n",
    "            imp = np.mean(np.abs(shap_vals), axis=0)\n",
    "            imp_df = pd.DataFrame({\n",
    "                \"feature\": feature_cols, \n",
    "                \"mean_abs_shap\": imp\n",
    "            })\n",
    "            imp_df = imp_df.sort_values(\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "            imp_df[\"dataset\"] = DATASET\n",
    "            imp_df[\"horizon\"] = horizon\n",
    "            imp_df[\"bucket\"] = bucket\n",
    "            all_rows.append(imp_df)\n",
    "\n",
    "            out_path = os.path.join(OUT_DIR, f\"shap_importance_{DATASET}_H{horizon}_{bucket}.csv\")\n",
    "            imp_df.to_csv(out_path, index=False)\n",
    "            print(f\"  ✓ Saved {out_path} | explained={len(X_ex)} | bg={len(X_bg)}\")\n",
    "\n",
    "    if not all_rows:\n",
    "        raise RuntimeError(\"No SHAP outputs produced; check models and data.\")\n",
    "\n",
    "    shap_all = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    TOPK = 15\n",
    "    topk = (\n",
    "        shap_all\n",
    "        .sort_values([\"horizon\", \"bucket\", \"mean_abs_shap\"], ascending=[True, True, False])\n",
    "        .groupby([\"dataset\", \"horizon\", \"bucket\"], as_index=False)\n",
    "        .head(TOPK)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"TOP SHAP FEATURES (mean |SHAP|) — per horizon & bucket\")\n",
    "    print(\"=\"*100)\n",
    "    print(topk)\n",
    "\n",
    "    topk_path = os.path.join(OUT_DIR, f\"shap_top{TOPK}_{DATASET}.csv\")\n",
    "    topk.to_csv(topk_path, index=False)\n",
    "    print(f\"\\n✓ Saved: {topk_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠ SHAP not available; using permutation importance as fallback.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218fbce",
   "metadata": {},
   "source": [
    "## Cell 14: LLM-Ready Artifact Packaging\n",
    "\n",
    "### Packaging Strategy\n",
    "We export model outputs and interpretability results to a structured JSON + CSV format ready for downstream LLM narration:\n",
    "- **Single JSON \"packet\"**: high-level metrics + top features (compact, LangGraph-friendly)\n",
    "- **Individual CSVs**: detailed per-split/per-bucket breakdowns (queryable by retrieval systems)\n",
    "- **Prompt templates**: system/user instructions for DeepSeek or other LLMs\n",
    "\n",
    "### Why This Separation?\n",
    "- LangGraph pipelines process JSON efficiently (no dataframe overhead)\n",
    "- RAG systems can retrieve detailed CSVs on demand\n",
    "- Prevents hallucination: LLM only sees data that actually exists in the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838f4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] LLM_outputs\\baseline_seasonal_naive_rows.csv  rows=30,358  cols=6\n",
      "[saved] LLM_outputs\\lgbm_segmented_bucket_metrics.csv  rows=6  cols=6\n",
      "[saved] LLM_outputs\\lgbm_segmented_weighted_metrics.csv  rows=2  cols=6\n",
      "[saved] LLM_outputs\\interpret_shap_importance_all.csv  rows=60  cols=6\n",
      "[saved] LLM_outputs\\llm_packet.json\n",
      "[saved] LLM_outputs\\prompt_system.txt\n",
      "[saved] LLM_outputs\\prompt_user.txt\n",
      "\n",
      "✓ LLM-ready artifacts packaged. Ready for downstream narration pipeline.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = Path(\"./LLM_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_write_df(df: pd.DataFrame, filename: str):\n",
    "    \"\"\"Write DataFrame to CSV, skip if None or empty.\"\"\"\n",
    "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return\n",
    "    out_path = OUT_DIR / filename\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"[saved] {out_path}  rows={len(df):,}  cols={df.shape[1]}\")\n",
    "\n",
    "def _safe_write_json(obj, filename: str):\n",
    "    \"\"\"Write JSON object, converting non-serializable types.\"\"\"\n",
    "    out_path = OUT_DIR / filename\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, default=str)\n",
    "    print(f\"[saved] {out_path}\")\n",
    "\n",
    "def _maybe_get_df(name: str):\n",
    "    \"\"\"Safely retrieve DataFrame from namespace.\"\"\"\n",
    "    return globals().get(name, None)\n",
    "\n",
    "# Export core metric tables\n",
    "_safe_write_df(_maybe_get_df(\"baseline_df\"), \"baseline_seasonal_naive_rows.csv\")\n",
    "_safe_write_df(_maybe_get_df(\"bucket_df\"), \"lgbm_segmented_bucket_metrics.csv\")\n",
    "_safe_write_df(_maybe_get_df(\"weighted_df\"), \"lgbm_segmented_weighted_metrics.csv\")\n",
    "\n",
    "# Aggregate and export SHAP summaries\n",
    "ART_DIR = Path(\"./artifacts_interpretability\")\n",
    "shap_top_files = sorted(ART_DIR.glob(\"shap_top*_*.csv\")) if ART_DIR.exists() else []\n",
    "shap_imp_files = sorted(ART_DIR.glob(\"shap_importance_*.csv\")) if ART_DIR.exists() else []\n",
    "\n",
    "def _concat_csvs(files):\n",
    "    \"\"\"Concatenate multiple CSV files, skip on read failure.\"\"\"\n",
    "    if not files:\n",
    "        return None\n",
    "    dfs_ = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            df_ = pd.read_csv(fp)\n",
    "            df_[\"source_file\"] = fp.name\n",
    "            dfs_.append(df_)\n",
    "        except Exception as e:\n",
    "            print(f\"  [warn] failed reading {fp}: {e}\")\n",
    "    if not dfs_:\n",
    "        return None\n",
    "    return pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "shap_imp_all = _concat_csvs(shap_imp_files)\n",
    "_safe_write_df(shap_imp_all, \"interpret_shap_importance_all.csv\")\n",
    "\n",
    "# Construct LLM packet: compact JSON with all key results\n",
    "packet = {}\n",
    "\n",
    "def _df_to_records(df):\n",
    "    \"\"\"Convert DataFrame to list of dicts, replace NaN with None for JSON.\"\"\"\n",
    "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return None\n",
    "    return df.replace({np.nan: None}).to_dict(orient=\"records\")\n",
    "\n",
    "# Package metrics\n",
    "packet[\"metrics\"] = {\n",
    "    \"baseline_summary\": _df_to_records(_maybe_get_df(\"summary\")) if isinstance(_maybe_get_df(\"summary\"), pd.DataFrame) else None,\n",
    "    \"lgbm_segmented_bucket_metrics\": _df_to_records(_maybe_get_df(\"bucket_df\")),\n",
    "    \"lgbm_segmented_weighted_metrics\": _df_to_records(_maybe_get_df(\"weighted_df\")),\n",
    "}\n",
    "\n",
    "# Package interpretability (top features only, not full importance)\n",
    "if shap_imp_all is not None and not shap_imp_all.empty:\n",
    "    top_feat = shap_imp_all.nlargest(15, \"mean_abs_shap\")  # Top 15 per bucket\n",
    "    packet[\"interpretability\"] = {\n",
    "        \"method\": \"shap\",\n",
    "        \"top_features\": _df_to_records(top_feat)\n",
    "    }\n",
    "else:\n",
    "    packet[\"interpretability\"] = {\"method\": None, \"top_features\": None}\n",
    "\n",
    "_safe_write_json(packet, \"llm_packet.json\")\n",
    "\n",
    "# Write prompt templates (instructions for LLM)\n",
    "SYSTEM_PROMPT = \"\"\"You are an analytics assistant interpreting hospital forecasting results.\n",
    "You must ONLY cite metrics and features present in the provided data.\n",
    "You must NOT forecast new values, hallucinate numbers, or invent insights.\n",
    "\n",
    "Output structure:\n",
    "1) Executive Summary: 3-5 key findings (MAE/RMSE improvements, bucket effects)\n",
    "2) Model Comparison: Baseline vs. ML across horizons\n",
    "3) Segment Insights: Small/Medium/Large hospital differences\n",
    "4) Top Drivers: Which features matter most (from SHAP)\n",
    "5) Recommendations: Deployment guidance based on data\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"Interpret the attached hospital forecasting outputs.\n",
    "\n",
    "Use ONLY the provided CSVs and JSON:\n",
    "- lgbm_segmented_weighted_metrics.csv: overall model performance\n",
    "- lgbm_segmented_bucket_metrics.csv: per-segment breakdown\n",
    "- baseline_seasonal_naive_rows.csv: baseline benchmark\n",
    "- interpret_shap_importance_all.csv: feature importance\n",
    "- llm_packet.json: executive summary packet\n",
    "\n",
    "Rules:\n",
    "- Do not invent metrics.\n",
    "- Do not hallucinate model details.\n",
    "- Explain WHY segmentation works (if it does) using the provided metrics.\n",
    "\"\"\"\n",
    "\n",
    "(OUT_DIR / \"prompt_system.txt\").write_text(SYSTEM_PROMPT, encoding=\"utf-8\")\n",
    "(OUT_DIR / \"prompt_user.txt\").write_text(USER_PROMPT, encoding=\"utf-8\")\n",
    "print(f\"[saved] {OUT_DIR / 'prompt_system.txt'}\")\n",
    "print(f\"[saved] {OUT_DIR / 'prompt_user.txt'}\")\n",
    "\n",
    "print(\"\\n✓ LLM-ready artifacts packaged. Ready for downstream narration pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3de03b",
   "metadata": {},
   "source": [
    "## Cell 15: LLM Input Preparation & DeepSeek Integration\n",
    "\n",
    "### Purpose\n",
    "This cell prepares a minimal context JSON from all computed metrics and feeds it to DeepSeek API for automated narrative generation.\n",
    "\n",
    "### Design Philosophy\n",
    "- **Constraints-Based**: LLM sees only facts (CSV data + JSON), no template boilerplate\n",
    "- **Fact-Checking Ready**: if LLM cites a metric, it's verifiable against source CSVs\n",
    "- **Deployable**: can be wrapped in LangGraph for multi-step reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d84c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING CONTEXT FOR LLM NARRATION...\n",
      "\n",
      "[Saved] baseline_metrics.csv\n",
      "[Saved] ml_segmented_buckets.csv\n",
      "[Saved] ml_segmented_weighted.csv\n",
      "[Saved] shap_top_drivers.csv\n",
      "\n",
      "✓ Context prepared in ./LLM_input\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "INPUT_DIR = \"./LLM_input\"\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "def safe_save(df, filename):\n",
    "    \"\"\"Save DataFrame to CSV for LLM consumption.\"\"\"\n",
    "    if df is not None and isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        path = os.path.join(INPUT_DIR, filename)\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"[Saved] {filename}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(\"PREPARING CONTEXT FOR LLM NARRATION...\\n\")\n",
    "\n",
    "# Save metric tables\n",
    "safe_save(globals().get('baseline_df'), \"baseline_metrics.csv\")\n",
    "safe_save(globals().get('bucket_df'), \"ml_segmented_buckets.csv\")\n",
    "safe_save(globals().get('weighted_df'), \"ml_segmented_weighted.csv\")\n",
    "safe_save(globals().get('topk'), \"shap_top_drivers.csv\")\n",
    "\n",
    "# Metadata\n",
    "context_note = {\n",
    "    \"project_scope\": \"Hospital Capacity Planning (Time Series Forecasting)\",\n",
    "    \"dataset\": \"hospital_dataset.tsf\",\n",
    "    \"horizons_months\": [6, 12],\n",
    "    \"constraints\": [\n",
    "        \"Only cite provided metrics; do not forecast new values.\",\n",
    "        \"Compare models on MAE (robustness) and RMSE (outlier penalty).\",\n",
    "        \"Explain segmentation benefits using provided metrics.\"\n",
    "    ],\n",
    "    \"generated_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(os.path.join(INPUT_DIR, \"context.json\"), \"w\") as f:\n",
    "    json.dump(context_note, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Context prepared in {INPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0e796",
   "metadata": {},
   "source": [
    "## Cell 16: Automated Narrative Generation via DeepSeek API\n",
    "\n",
    "### Workflow\n",
    "1. **Load Metrics**: read CSV files and context JSON\n",
    "2. **Construct Prompt**: system (role) + user (task) combine to guide narration\n",
    "3. **Call DeepSeek**: remote API generates structured report\n",
    "4. **Persist Output**: save narrative for stakeholder review\n",
    "\n",
    "### Key Principle\n",
    "The LLM acts as a **lazy summarizer**, not a researcher. It does not:\n",
    "- Retrain models\n",
    "- Compute new metrics\n",
    "- Invent thresholds\n",
    "\n",
    "Instead, it:\n",
    "- Interprets provided metrics\n",
    "- Connects findings to hospital domain (e.g., \"large facilities need 12-month forecasts\")\n",
    "- Recommends based on observed performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98a524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Contacting DeepSeek Reasoner (Thinking Model)...\n",
      "--------------------------------------------------------------------------------\n",
      "# Hospital Forecasting Pipeline Analysis\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "The analysis reveals a **critical failure mode in the \"Large\" hospital segment** that dramatically degrades overall performance of the Segmented ML approach. While Classical ETS provides consistent moderate performance across all hospital sizes, the Segmented ML model catastrophically fails for large hospitals despite strong performance on small and medium hospitals. The Large bucket's RMSE (89.26) is **4-5x worse** than Classical ETS (21.78), indicating a fundamental mismatch between the ML model and large-hospital patterns.\n",
      "\n",
      "## Leaderboard: Ranked by Robustness\n",
      "\n",
      "### 1. **Classical ETS** (Most Robust)\n",
      "- **Overall MAE**: 18.59-20.49 | **Overall RMSE**: 21.78-24.42\n",
      "- **Strengths**: Consistent performance across all hospital scales, no catastrophic failures\n",
      "- **Weaknesses**: Moderate accuracy, not best-in-class for any segment\n",
      "- **Reliability Score**: 9/10\n",
      "\n",
      "### 2. **Segmented ML for Small Hospitals** (Best for Segment)\n",
      "- **Small Bucket MAE**: 3.62-3.72 | **RMSE**: 4.79-4.93\n",
      "- **Strengths**: Outstanding accuracy for low-volume hospitals\n",
      "- **Weaknesses**: Only applicable to small hospitals\n",
      "- **Reliability Score**: 8/10\n",
      "\n",
      "### 3. **Segmented ML for Medium Hospitals**\n",
      "- **Medium Bucket MAE**: 6.25-6.40 | **RMSE**: 8.56-8.81\n",
      "- **Strengths**: Good performance for medium-volume hospitals\n",
      "- **Weaknesses**: Only applicable to medium hospitals\n",
      "- **Reliability Score**: 7/10\n",
      "\n",
      "### 4. **Segmented ML for Large Hospitals** (Least Robust)\n",
      "- **Large Bucket MAE**: 38.95-39.82 | **RMSE**: 89.26-89.12\n",
      "- **Strengths**: None identified\n",
      "- **Weaknesses**: Catastrophic failure, unacceptable error magnitudes\n",
      "- **Reliability Score**: 1/10\n",
      "\n",
      "## Deep Dive: The Large Hospital Failure Mode\n",
      "\n",
      "### Critical Failure Metrics\n",
      "- **RMSE of 89.26** for horizon 6 (vs. 21.78 for ETS) - **309% worse**\n",
      "- **MAE of 38.95** for horizon 6 (vs. 18.59 for ETS) - **109% worse**\n",
      "- **Error Pattern**: High RMSE relative to MAE suggests extreme outlier errors rather than consistent bias\n",
      "\n",
      "### Root Cause Analysis\n",
      "1. **Scale Mismatch**: The log1p transformation may be insufficient for large-hospital dynamics where volume fluctuations are multiplicative rather than additive\n",
      "2. **Feature Inadequacy**: Large hospitals show complex patterns not captured by simple lag/roll features\n",
      "3. **Data Sparsity**: Possibly fewer large hospitals in training data, leading to poor generalization\n",
      "\n",
      "## Driver Analysis: Feature Importance by Hospital Scale\n",
      "\n",
      "### Large Hospitals (Failed Model)\n",
      "- **Primary Drivers**: `lag_1` (0.368) and `roll_mean_3` (0.306)\n",
      "- **Pattern**: Over-reliance on very recent history (lag1 dominates lag12 by 3.3x)\n",
      "- **Insight**: Model assumes strong short-term autocorrelation that doesn't hold for large hospitals\n",
      "- **Missing**: Long-term seasonality and external factors that likely drive large hospital volumes\n",
      "\n",
      "### Medium Hospitals (Good Model)\n",
      "- **Balanced Drivers**: `roll_mean_3` (0.132) > `lag_1` (0.083) > `roll_mean_12` (0.077)\n",
      "- **Pattern**: Healthy mix of short-term and seasonal features\n",
      "- **Why It Works**: Appropriate feature balance matches medium-hospital dynamics\n",
      "\n",
      "### Small Hospitals (Excellent Model)\n",
      "- **Primary Driver**: `roll_mean_12` (0.102) - seasonal patterns dominate\n",
      "- **Pattern**: Strong seasonal dependence with less noise\n",
      "- **Why It Works**: Small hospitals follow predictable seasonal patterns well-captured by rolling averages\n",
      "\n",
      "### Critical Observation\n",
      "The **feature importance ratio gap** reveals the failure:\n",
      "- Large: `lag_1`/`lag_12` = 3.31 (over-indexed on immediate past)\n",
      "- Medium: `lag_1`/`lag_12` = 3.70 (balanced but slightly better)\n",
      "- Small: `roll_mean_3`/`roll_mean_12` = 0.79 (proper seasonal focus)\n",
      "\n",
      "## Final Recommendation\n",
      "\n",
      "### Immediate Action (Next Sprint)\n",
      "1. **Remove Segmented ML for Large Hospitals**: Immediately revert to Classical ETS for the large bucket\n",
      "2. **Implement Hybrid Approach**:\n",
      "   - Large hospitals: Classical ETS (robust, moderate accuracy)\n",
      "   - Medium hospitals: Segmented ML (good accuracy)\n",
      "   - Small hospitals: Segmented ML (excellent accuracy)\n",
      "3. **This hybrid yields estimated overall MAE: ~10-12, RMSE: ~15-18** - beating pure ETS by 30-40%\n",
      "\n",
      "### Medium-Term Strategy\n",
      "1. **Large-Hospital Specific Modeling**:\n",
      "   - Test alternative transformations (log vs log1p)\n",
      "   - Add features: day-of-week effects, holiday indicators, epidemiological factors\n",
      "   - Consider hierarchical reconciliation methods\n",
      "2. **Feature Engineering**:\n",
      "   - For large hospitals: Add volatility measures, regime-change indicators\n",
      "   - For all hospitals: Incorporate external data (weather, local events)\n",
      "\n",
      "### Long-Term Vision\n",
      "1. **Architecture Change**: Move to a unified global model with hospital-scale embeddings rather than segmented training\n",
      "2. **Uncertainty Quantification**: Implement prediction intervals, especially critical for large hospitals\n",
      "3. **Continuous Monitoring**: Establish bucket-specific performance dashboards with automatic alerting\n",
      "\n",
      "**Bottom Line**: The Segmented ML approach is promising but requires bucket-specific tuning. The current implementation fails catastrophically for large hospitals, making a hybrid ETS+ML approach the optimal immediate solution while longer-term fixes are developed.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ Thinking report saved to: ./Deepseek_results\\hospital_thinking_narrative_raw.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIG: API & OUTPUT\n",
    "# ---------------------------------------------------------\n",
    "DEEPSEEK_API_KEY = \"add any openAI/deepseek api key here\" \n",
    "\n",
    "OUTPUT_DIR = \"./Deepseek_results\"\n",
    "INPUT_DIR = \"./LLM_input\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. RAW CONTENT LOADER (WITH TOKEN SAFETY)\n",
    "# ---------------------------------------------------------\n",
    "def get_raw_content(filename, max_rows=200):\n",
    "    path = os.path.join(INPUT_DIR, filename)\n",
    "    if not os.path.exists(path):\n",
    "        return \"Data not found.\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # CASE A: Small, high-value files (SHAP, Segmented Metrics, ETS)\n",
    "        # We want the LLM to see EVERY row here, especially for SHAP feature names.\n",
    "        if len(df) < max_rows:\n",
    "            return df.to_string(index=False)\n",
    "        \n",
    "        # CASE B: Massive files (Row-level Baseline/Global backtests)\n",
    "        # We cannot send 30k rows (800k tokens). We sample the head/tail to show structure.\n",
    "        else:\n",
    "            return (\n",
    "                f\"Note: File has {len(df)} rows. Showing first {max_rows} rows only:\\n\" +\n",
    "                df.head(max_rows).to_string(index=False) + \n",
    "                \"\\n... [TRUNCATED DUE TO CONTEXT LIMIT] ...\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "# Load raw strings. Note we don't use 'describe()' anymore.\n",
    "context_str = f\"\"\"\n",
    "PROJECT METADATA:\n",
    "{get_raw_content('context.json')}\n",
    "\n",
    "MODEL PERFORMANCE (RAW DATA):\n",
    "- Baseline (Seasonal Naive) [Sampled]: \n",
    "{get_raw_content('baseline_metrics.csv', max_rows=50)}\n",
    "\n",
    "- Classical (ETS): \n",
    "{get_raw_content('ets_metrics.csv')}\n",
    "\n",
    "- Global ML Metrics: \n",
    "{get_raw_content('ml_global_metrics.csv')}\n",
    "\n",
    "- Segmented ML (Buckets) [CRITICAL]: \n",
    "{get_raw_content('ml_segmented_buckets.csv')}\n",
    "\n",
    "- Segmented ML (Weighted Overall): \n",
    "{get_raw_content('ml_segmented_weighted.csv')}\n",
    "\n",
    "INTERPRETABILITY (SHAP TOP DRIVERS) [FULL LIST]:\n",
    "{get_raw_content('shap_top_drivers.csv', max_rows=1000)} \n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. CONSTRUCT PROMPT\n",
    "# ---------------------------------------------------------\n",
    "# We emphasize to the model that it is looking at raw data segments.\n",
    "system_prompt = \"\"\"You are a Principal Data Scientist. \n",
    "You are analyzing the RAW output metrics from a Hospital Forecasting Pipeline.\n",
    "\n",
    "OBJECTIVES:\n",
    "1. Compare Classical ETS vs. Segmented ML. \n",
    "2. Diagnose the specific failure in the 'Large' hospital bucket using the raw metrics.\n",
    "3. Look at the SHAP table to identify WHICH features (lag vs roll) drive specific segments.\n",
    "\n",
    "OUTPUT STRUCTURE:\n",
    "- Executive Summary\n",
    "- Leaderboard (Rank models by robustness)\n",
    "- Deep Dive: The Large Hospital Failure Mode (Cite specific RMSE/MAE values)\n",
    "- Driver Analysis: Mapping feature importance to hospital scale\n",
    "- Final Recommendation\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"Analyze these raw results:\\n\\n{context_str}\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. CALL DEEPSEEK REASONER\n",
    "# ---------------------------------------------------------\n",
    "print(\"⏳ Contacting DeepSeek Reasoner (Thinking Model)...\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DEEPSEEK_API_KEY, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-reasoner\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    narrative = response.choices[0].message.content\n",
    "    \n",
    "    out_path = os.path.join(OUTPUT_DIR, \"hospital_thinking_narrative_raw.md\")\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(narrative)\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(narrative)\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"\\n✅ Thinking report saved to: {out_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ API Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp3env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
