{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c4db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 .tsf files:\n",
      "\n",
      "electricity_weekly_dataset.tsf\n",
      "hospital_dataset.tsf\n",
      "tourism_monthly_dataset.tsf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all .tsf files in the current directory\n",
    "tsf_files = [f for f in os.listdir('.') if f.lower().endswith('.tsf')]\n",
    "\n",
    "# Sort for readability\n",
    "tsf_files.sort()\n",
    "\n",
    "print(f\"Found {len(tsf_files)} .tsf files:\\n\")\n",
    "for f in tsf_files:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce15474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "FILE: hospital_dataset.tsf\n",
      "------------------------------------------------------------------------------------------\n",
      "@relation: Hospital\n",
      "@frequency: monthly\n",
      "@missing: false\n",
      "@equallength: true\n",
      "\n",
      "@attributes:\n",
      "  - series_name (string)\n",
      "  - start_timestamp (date)\n",
      "\n",
      "Data scan (limited):\n",
      "  Series rows scanned: 767\n",
      "  Series length min/median/max: 84 / 84 / 84\n",
      "  Numeric parse failures (sampled values): 0\n",
      "\n",
      "Preview:\n",
      "  - series_name=T1 | start_timestamp=2000-01-01 00-00-00\n",
      "  - series_name=T2 | start_timestamp=2000-01-01 00-00-00\n",
      "  - series_name=T3 | start_timestamp=2000-01-01 00-00-00\n",
      "==========================================================================================\n",
      "FILE: tourism_monthly_dataset.tsf\n",
      "------------------------------------------------------------------------------------------\n",
      "@relation: Tourism\n",
      "@frequency: monthly\n",
      "@horizon: 24\n",
      "@missing: false\n",
      "@equallength: false\n",
      "\n",
      "@attributes:\n",
      "  - series_name (string)\n",
      "  - start_timestamp (date)\n",
      "\n",
      "Data scan (limited):\n",
      "  Series rows scanned: 366\n",
      "  Series length min/median/max: 91 / 330 / 333\n",
      "  Numeric parse failures (sampled values): 0\n",
      "\n",
      "Preview:\n",
      "  - series_name=T1 | start_timestamp=1979-01-01 00-00-00\n",
      "  - series_name=T2 | start_timestamp=1979-01-01 00-00-00\n",
      "  - series_name=T3 | start_timestamp=1985-01-01 00-00-00\n",
      "==========================================================================================\n",
      "FILE: electricity_weekly_dataset.tsf\n",
      "------------------------------------------------------------------------------------------\n",
      "@relation: Electricity\n",
      "@frequency: weekly\n",
      "@horizon: 8\n",
      "@missing: false\n",
      "@equallength: true\n",
      "\n",
      "@attributes:\n",
      "  - series_name (string)\n",
      "  - start_timestamp (date)\n",
      "\n",
      "Data scan (limited):\n",
      "  Series rows scanned: 321\n",
      "  Series length min/median/max: 156 / 156 / 156\n",
      "  Numeric parse failures (sampled values): 0\n",
      "\n",
      "Preview:\n",
      "  - series_name=T1 | start_timestamp=2012-01-01 00-00-00\n",
      "  - series_name=T2 | start_timestamp=2012-01-01 00-00-00\n",
      "  - series_name=T3 | start_timestamp=2012-01-01 00-00-00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "TSF_FILES = [\n",
    "    \"hospital_dataset.tsf\",\n",
    "    \"tourism_monthly_dataset.tsf\",\n",
    "    \"electricity_weekly_dataset.tsf\",\n",
    "]\n",
    "\n",
    "def parse_tsf(filepath, max_series_preview=3):\n",
    "    \"\"\"\n",
    "    Lightweight .tsf inspector:\n",
    "    - reads header comments (# ...)\n",
    "    - reads @metadata fields (e.g., @frequency, @horizon, @missing, @equallength)\n",
    "    - reads @attribute lines\n",
    "    - samples a few @data rows to summarize series lengths and value parsing\n",
    "    Does NOT load entire file into memory as a full dataframe (fast + safe).\n",
    "    \"\"\"\n",
    "    meta = {}\n",
    "    attributes = []\n",
    "    header_comments = []\n",
    "    in_data = False\n",
    "    series_lengths = []\n",
    "    series_names_preview = []\n",
    "    start_timestamps_preview = []\n",
    "    numeric_parse_failures = 0\n",
    "\n",
    "    # TSF @attribute format: \"@attribute <name> <type>\"\n",
    "    attr_pat = re.compile(r\"^@attribute\\s+(\\S+)\\s+(\\S+)\", re.IGNORECASE)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line.startswith(\"#\") and not in_data:\n",
    "                header_comments.append(line)\n",
    "                continue\n",
    "\n",
    "            if line.lower().startswith(\"@data\"):\n",
    "                in_data = True\n",
    "                continue\n",
    "\n",
    "            if not in_data:\n",
    "                if line.lower().startswith(\"@attribute\"):\n",
    "                    m = attr_pat.match(line)\n",
    "                    if m:\n",
    "                        attributes.append((m.group(1), m.group(2)))\n",
    "                    continue\n",
    "\n",
    "                if line.startswith(\"@\"):\n",
    "                    # e.g., @frequency weekly\n",
    "                    parts = line.split(None, 1)\n",
    "                    key = parts[0].lstrip(\"@\").strip().lower()\n",
    "                    val = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "                    meta[key] = val\n",
    "                continue\n",
    "\n",
    "            # Data row example:\n",
    "            # series_name:start_timestamp:val1,val2,val3,...\n",
    "            # Some datasets may omit timestamps or use different separators; handle robustly.\n",
    "            if in_data:\n",
    "                # stop after previewing a few series to keep it fast\n",
    "                if len(series_lengths) >= 5000 and max_series_preview == 0:\n",
    "                    break\n",
    "\n",
    "                # Split first two \":\" occurrences\n",
    "                parts = line.split(\":\", 2)\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "\n",
    "                sname = parts[0]\n",
    "                series_names_preview.append(sname) if len(series_names_preview) < max_series_preview else None\n",
    "\n",
    "                if len(parts) == 2:\n",
    "                    # no timestamp field, just values\n",
    "                    values_str = parts[1]\n",
    "                else:\n",
    "                    ts = parts[1]\n",
    "                    values_str = parts[2]\n",
    "                    if len(start_timestamps_preview) < max_series_preview:\n",
    "                        start_timestamps_preview.append(ts)\n",
    "\n",
    "                values = [v.strip() for v in values_str.split(\",\") if v.strip() != \"\"]\n",
    "                series_lengths.append(len(values))\n",
    "\n",
    "                # quick numeric parse check (sample first 20 values)\n",
    "                for v in values[:20]:\n",
    "                    try:\n",
    "                        float(v)\n",
    "                    except:\n",
    "                        numeric_parse_failures += 1\n",
    "\n",
    "                # only preview a few series rows (not entire file) for speed\n",
    "                if len(series_lengths) >= max_series_preview and max_series_preview > 0:\n",
    "                    # keep scanning to get length stats? If you want full stats, set max_series_preview=0\n",
    "                    pass\n",
    "\n",
    "    summary = {\n",
    "        \"file\": os.path.basename(filepath),\n",
    "        \"meta\": meta,\n",
    "        \"attributes\": attributes,\n",
    "        \"header_comment_lines\": len(header_comments),\n",
    "        \"series_count_estimate\": len(series_lengths),\n",
    "        \"series_length_min\": min(series_lengths) if series_lengths else None,\n",
    "        \"series_length_median\": (sorted(series_lengths)[len(series_lengths)//2] if series_lengths else None),\n",
    "        \"series_length_max\": max(series_lengths) if series_lengths else None,\n",
    "        \"numeric_parse_failures_in_sample\": numeric_parse_failures,\n",
    "        \"series_name_preview\": series_names_preview[:max_series_preview],\n",
    "        \"start_timestamp_preview\": start_timestamps_preview[:max_series_preview],\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "def print_summary(s):\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"FILE: {s['file']}\")\n",
    "    print(\"-\" * 90)\n",
    "\n",
    "    # Metadata fields commonly used in Monash TSF\n",
    "    for k in [\"relation\", \"frequency\", \"horizon\", \"missing\", \"equallength\"]:\n",
    "        if k in s[\"meta\"]:\n",
    "            print(f\"@{k}: {s['meta'][k]}\")\n",
    "    # Print any additional meta keys not in the common list\n",
    "    other_keys = [k for k in s[\"meta\"].keys() if k not in {\"relation\",\"frequency\",\"horizon\",\"missing\",\"equallength\"}]\n",
    "    if other_keys:\n",
    "        print(\"Other @meta:\")\n",
    "        for k in sorted(other_keys):\n",
    "            print(f\"  @{k}: {s['meta'][k]}\")\n",
    "\n",
    "    print(\"\\n@attributes:\")\n",
    "    if s[\"attributes\"]:\n",
    "        for name, typ in s[\"attributes\"]:\n",
    "            print(f\"  - {name} ({typ})\")\n",
    "    else:\n",
    "        print(\"  (none found)\")\n",
    "\n",
    "    print(\"\\nData scan (limited):\")\n",
    "    print(f\"  Series rows scanned: {s['series_count_estimate']}\")\n",
    "    print(f\"  Series length min/median/max: {s['series_length_min']} / {s['series_length_median']} / {s['series_length_max']}\")\n",
    "    print(f\"  Numeric parse failures (sampled values): {s['numeric_parse_failures_in_sample']}\")\n",
    "\n",
    "    print(\"\\nPreview:\")\n",
    "    for i, name in enumerate(s[\"series_name_preview\"]):\n",
    "        ts = s[\"start_timestamp_preview\"][i] if i < len(s[\"start_timestamp_preview\"]) else \"(no timestamp field)\"\n",
    "        print(f\"  - series_name={name} | start_timestamp={ts}\")\n",
    "\n",
    "# --- RUN INSPECTION ---\n",
    "for fn in TSF_FILES:\n",
    "    path = Path(\"./\") / fn\n",
    "    if not path.exists():\n",
    "        print(f\"[MISSING] {fn} not found in current directory.\")\n",
    "        continue\n",
    "    summary = parse_tsf(path, max_series_preview=3)\n",
    "    print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd91ec6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "hospital_dataset.tsf\n",
      "shape: (64428, 4)\n",
      "columns: ['dataset', 'series_name', 'timestamp', 'y']\n",
      "n_series: 767\n",
      "date_range: 2000-01-01 00:00:00+00:00 -> 2006-12-01 00:00:00+00:00\n",
      "missing_y: 0\n",
      "                dataset series_name                 timestamp   y\n",
      "0  hospital_dataset.tsf          T1 2000-01-01 00:00:00+00:00  27\n",
      "1  hospital_dataset.tsf          T1 2000-02-01 00:00:00+00:00  16\n",
      "2  hospital_dataset.tsf          T1 2000-03-01 00:00:00+00:00  18\n",
      "================================================================================\n",
      "tourism_monthly_dataset.tsf\n",
      "shape: (109280, 4)\n",
      "columns: ['dataset', 'series_name', 'timestamp', 'y']\n",
      "n_series: 366\n",
      "date_range: 1979-01-01 00:00:00+00:00 -> 2007-09-01 00:00:00+00:00\n",
      "missing_y: 0\n",
      "                       dataset series_name                 timestamp  \\\n",
      "0  tourism_monthly_dataset.tsf          T1 1979-01-01 00:00:00+00:00   \n",
      "1  tourism_monthly_dataset.tsf          T1 1979-02-01 00:00:00+00:00   \n",
      "2  tourism_monthly_dataset.tsf          T1 1979-03-01 00:00:00+00:00   \n",
      "\n",
      "           y  \n",
      "0  1149.8700  \n",
      "1  1053.8002  \n",
      "2  1388.8798  \n",
      "================================================================================\n",
      "electricity_weekly_dataset.tsf\n",
      "shape: (50076, 4)\n",
      "columns: ['dataset', 'series_name', 'timestamp', 'y']\n",
      "n_series: 321\n",
      "date_range: 2012-01-01 00:00:00+00:00 -> 2014-12-21 00:00:00+00:00\n",
      "missing_y: 0\n",
      "                          dataset series_name                 timestamp     y\n",
      "0  electricity_weekly_dataset.tsf          T1 2012-01-01 00:00:00+00:00  8032\n",
      "1  electricity_weekly_dataset.tsf          T1 2012-01-08 00:00:00+00:00  9097\n",
      "2  electricity_weekly_dataset.tsf          T1 2012-01-15 00:00:00+00:00  9394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "TSF_FILES = [\n",
    "    \"hospital_dataset.tsf\",\n",
    "    \"tourism_monthly_dataset.tsf\",\n",
    "    \"electricity_weekly_dataset.tsf\",\n",
    "]\n",
    "\n",
    "def parse_tsf_to_long_df(path: str) -> pd.DataFrame:\n",
    "    meta = {}\n",
    "    in_data = False\n",
    "    rows = []\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            if line.lower().startswith(\"@data\"):\n",
    "                in_data = True\n",
    "                continue\n",
    "\n",
    "            if not in_data:\n",
    "                if line.startswith(\"@\"):\n",
    "                    parts = line.split(None, 1)\n",
    "                    key = parts[0].lstrip(\"@\").strip().lower()\n",
    "                    val = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "                    meta[key] = val\n",
    "                continue\n",
    "\n",
    "            # data line: series_name:start_timestamp:val1,val2,...\n",
    "            parts = line.split(\":\", 2)\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "\n",
    "            series_name = parts[0]\n",
    "            if len(parts) == 2:\n",
    "                start_ts = None\n",
    "                values_str = parts[1]\n",
    "            else:\n",
    "                start_ts = parts[1]\n",
    "                values_str = parts[2]\n",
    "\n",
    "            values = [v.strip() for v in values_str.split(\",\") if v.strip() != \"\"]\n",
    "            y = pd.to_numeric(pd.Series(values), errors=\"coerce\")\n",
    "\n",
    "            freq = meta.get(\"frequency\", \"\").lower()\n",
    "            if start_ts is None:\n",
    "                # fallback: index-based timestamps\n",
    "                t = pd.RangeIndex(len(y))\n",
    "            else:\n",
    "                start = pd.to_datetime(start_ts.replace(\"-\", \":\"), errors=\"coerce\")  # tsf uses \"00-00-00\"\n",
    "                if pd.isna(start):\n",
    "                    start = pd.to_datetime(start_ts, errors=\"coerce\")\n",
    "\n",
    "                if freq == \"monthly\":\n",
    "                    t = pd.date_range(start=start, periods=len(y), freq=\"MS\")\n",
    "                elif freq == \"weekly\":\n",
    "                    t = pd.date_range(start=start, periods=len(y), freq=\"W-SUN\")\n",
    "                else:\n",
    "                    # generic fallback\n",
    "                    t = pd.date_range(start=start, periods=len(y), freq=\"D\")\n",
    "\n",
    "            df_part = pd.DataFrame({\n",
    "                \"dataset\": Path(path).name,\n",
    "                \"series_name\": series_name,\n",
    "                \"timestamp\": t,\n",
    "                \"y\": y.values\n",
    "            })\n",
    "            rows.append(df_part)\n",
    "\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    return out\n",
    "\n",
    "dfs = {}\n",
    "for fn in TSF_FILES:\n",
    "    df = parse_tsf_to_long_df(fn)\n",
    "    dfs[fn] = df\n",
    "    print(\"=\"*80)\n",
    "    print(fn)\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(\"columns:\", df.columns.tolist())\n",
    "    print(\"n_series:\", df[\"series_name\"].nunique())\n",
    "    print(\"date_range:\", df[\"timestamp\"].min(), \"->\", df[\"timestamp\"].max())\n",
    "    print(\"missing_y:\", df[\"y\"].isna().sum())\n",
    "    print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df40174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ROLLING BACKTEST SUMMARY\n",
      "==========================================================================================\n",
      "                          dataset  horizon  n_splits  n_series  \\\n",
      "0  electricity_weekly_dataset.tsf        8        12       321   \n",
      "1            hospital_dataset.tsf        6        11       767   \n",
      "2            hospital_dataset.tsf       12         9       767   \n",
      "3     tourism_monthly_dataset.tsf       24        36       365   \n",
      "\n",
      "  first_train_end last_test_end  \n",
      "0      2013-12-22    2014-12-21  \n",
      "1      2003-12-01    2006-12-01  \n",
      "2      2003-12-01    2006-12-01  \n",
      "3      1986-12-01    2007-06-01  \n",
      "\n",
      "Leakage check (train_end < test_start for all splits): True\n",
      "\n",
      "Sample splits:\n",
      "                dataset series_name  horizon  split_id  train_end test_start  \\\n",
      "0  hospital_dataset.tsf          T1        6         0 2003-12-01 2004-01-01   \n",
      "1  hospital_dataset.tsf          T1        6         1 2004-03-01 2004-04-01   \n",
      "2  hospital_dataset.tsf          T1        6         2 2004-06-01 2004-07-01   \n",
      "3  hospital_dataset.tsf          T1        6         3 2004-09-01 2004-10-01   \n",
      "4  hospital_dataset.tsf          T1        6         4 2004-12-01 2005-01-01   \n",
      "\n",
      "    test_end  \n",
      "0 2004-06-01  \n",
      "1 2004-09-01  \n",
      "2 2004-12-01  \n",
      "3 2005-03-01  \n",
      "4 2005-06-01  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG (LOCKED)\n",
    "# -----------------------------\n",
    "DATASETS = {\n",
    "    \"hospital_dataset.tsf\": {\n",
    "        \"freq\": \"MS\",      # monthly start\n",
    "        \"horizons\": [6, 12],\n",
    "        \"min_train_periods\": 48,  # 4 years\n",
    "        \"step\": 3          # months between rollings\n",
    "    },\n",
    "    \"tourism_monthly_dataset.tsf\": {\n",
    "        \"freq\": \"MS\",\n",
    "        \"horizons\": [24],\n",
    "        \"min_train_periods\": 96,  # 8 years (handles unequal length)\n",
    "        \"step\": 6\n",
    "    },\n",
    "    \"electricity_weekly_dataset.tsf\": {\n",
    "        \"freq\": \"W-SUN\",\n",
    "        \"horizons\": [8],\n",
    "        \"min_train_periods\": 104, # 2 years\n",
    "        \"step\": 4                 # weeks\n",
    "    }\n",
    "}\n",
    "\n",
    "def build_rolling_splits(df, dataset_name, cfg):\n",
    "    \"\"\"\n",
    "    Builds rolling-origin splits PER SERIES.\n",
    "    Returns a DataFrame with one row per split:\n",
    "    series_name | split_id | train_end | test_start | test_end | horizon\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    freq = cfg[\"freq\"]\n",
    "    step = cfg[\"step\"]\n",
    "    min_train = cfg[\"min_train_periods\"]\n",
    "\n",
    "    for horizon in cfg[\"horizons\"]:\n",
    "        for s, g in df[df[\"dataset\"] == dataset_name].groupby(\"series_name\"):\n",
    "            g = g.sort_values(\"timestamp\")\n",
    "            times = g[\"timestamp\"].values\n",
    "            n = len(times)\n",
    "\n",
    "            # compute rolling cutoff indices\n",
    "            cutoff_idxs = list(range(min_train - 1, n - horizon, step))\n",
    "            for i, cut_idx in enumerate(cutoff_idxs):\n",
    "                train_end = times[cut_idx]\n",
    "                test_start = times[cut_idx + 1]\n",
    "                test_end = times[cut_idx + horizon]\n",
    "\n",
    "                rows.append({\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"series_name\": s,\n",
    "                    \"horizon\": horizon,\n",
    "                    \"split_id\": i,\n",
    "                    \"train_end\": pd.Timestamp(train_end),\n",
    "                    \"test_start\": pd.Timestamp(test_start),\n",
    "                    \"test_end\": pd.Timestamp(test_end)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# -----------------------------\n",
    "# BUILD SPLITS\n",
    "# -----------------------------\n",
    "all_splits = []\n",
    "for name, cfg in DATASETS.items():\n",
    "    df = dfs[name]\n",
    "    splits = build_rolling_splits(df, name, cfg)\n",
    "    all_splits.append(splits)\n",
    "\n",
    "splits_df = pd.concat(all_splits, ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# VERIFICATION SUMMARY\n",
    "# -----------------------------\n",
    "summary = (\n",
    "    splits_df\n",
    "    .groupby([\"dataset\", \"horizon\"])\n",
    "    .agg(\n",
    "        n_splits=(\"split_id\", \"nunique\"),\n",
    "        n_series=(\"series_name\", \"nunique\"),\n",
    "        first_train_end=(\"train_end\", \"min\"),\n",
    "        last_test_end=(\"test_end\", \"max\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ROLLING BACKTEST SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(summary)\n",
    "\n",
    "# Leakage sanity check (should always be true)\n",
    "leakage_check = (splits_df[\"train_end\"] < splits_df[\"test_start\"]).all()\n",
    "print(\"\\nLeakage check (train_end < test_start for all splits):\", leakage_check)\n",
    "\n",
    "print(\"\\nSample splits:\")\n",
    "print(splits_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff59e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "SEASONAL NAIVE BASELINE RESULTS\n",
      "==========================================================================================\n",
      "                          dataset  horizon           MAE          RMSE\n",
      "0  electricity_weekly_dataset.tsf        8  33504.051629  39984.900267\n",
      "1            hospital_dataset.tsf        6     21.819545     26.014796\n",
      "2            hospital_dataset.tsf       12     21.788582     27.021620\n",
      "3     tourism_monthly_dataset.tsf       24   2006.442369   2521.121274\n",
      "\n",
      "Rows evaluated: 30358\n",
      "Any NaNs in metrics: {'mae': False, 'rmse': False}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# FIX TIMEZONE MISMATCH (LOCKED)\n",
    "# Convert all timestamps in dfs + splits_df to tz-naive consistently\n",
    "# -----------------------------\n",
    "def make_tz_naive(ts: pd.Series) -> pd.Series:\n",
    "    ts = pd.to_datetime(ts, errors=\"coerce\")\n",
    "    # If tz-aware, drop tz; if already naive, this is a no-op\n",
    "    try:\n",
    "        return ts.dt.tz_localize(None)\n",
    "    except AttributeError:\n",
    "        # In case it's already a DatetimeIndex-like without .dt\n",
    "        return ts.dt.tz_localize(None)\n",
    "\n",
    "# Apply to dfs\n",
    "for k in list(dfs.keys()):\n",
    "    dfs[k][\"timestamp\"] = pd.to_datetime(dfs[k][\"timestamp\"], errors=\"coerce\")\n",
    "    if getattr(dfs[k][\"timestamp\"].dt, \"tz\", None) is not None:\n",
    "        dfs[k][\"timestamp\"] = dfs[k][\"timestamp\"].dt.tz_localize(None)\n",
    "\n",
    "# Apply to splits_df\n",
    "for col in [\"train_end\", \"test_start\", \"test_end\"]:\n",
    "    splits_df[col] = pd.to_datetime(splits_df[col], errors=\"coerce\")\n",
    "    if getattr(splits_df[col].dt, \"tz\", None) is not None:\n",
    "        splits_df[col] = splits_df[col].dt.tz_localize(None)\n",
    "\n",
    "# -----------------------------\n",
    "# SEASONAL NAIVE\n",
    "# -----------------------------\n",
    "def seasonal_naive_forecast(y_train: np.ndarray, horizon: int, season_lag: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Seasonal naive forecast:\n",
    "    repeats the last observed seasonal cycle.\n",
    "    \"\"\"\n",
    "    y_train = np.asarray(y_train, dtype=float)\n",
    "    if len(y_train) == 0:\n",
    "        return np.full(horizon, np.nan)\n",
    "\n",
    "    if len(y_train) < season_lag:\n",
    "        # fallback to last value\n",
    "        return np.repeat(y_train[-1], horizon)\n",
    "\n",
    "    last_season = y_train[-season_lag:]  # length season_lag\n",
    "    reps = int(np.ceil(horizon / season_lag))\n",
    "    y_hat = np.tile(last_season, reps)[:horizon]\n",
    "    return y_hat\n",
    "\n",
    "def evaluate_seasonal_naive(df_long, splits_df, dataset_name, freq):\n",
    "    season_lag = 12 if freq == \"monthly\" else 52\n",
    "    df_ds = df_long[df_long[\"dataset\"] == dataset_name]\n",
    "\n",
    "    rows = []\n",
    "    for _, s in splits_df[splits_df[\"dataset\"] == dataset_name].iterrows():\n",
    "        g = df_ds[df_ds[\"series_name\"] == s[\"series_name\"]].sort_values(\"timestamp\")\n",
    "\n",
    "        train = g[g[\"timestamp\"] <= s[\"train_end\"]]\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) & (g[\"timestamp\"] <= s[\"test_end\"])]\n",
    "\n",
    "        y_true = test[\"y\"].astype(float).values\n",
    "        y_hat  = seasonal_naive_forecast(train[\"y\"].astype(float).values, int(s[\"horizon\"]), season_lag)\n",
    "\n",
    "        # Safety: ensure lengths match\n",
    "        if len(y_true) != len(y_hat):\n",
    "            # This should not happen; if it does, skip + record\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"dataset\": dataset_name,\n",
    "            \"horizon\": int(s[\"horizon\"]),\n",
    "            \"series_name\": s[\"series_name\"],\n",
    "            \"split_id\": int(s[\"split_id\"]),\n",
    "            \"mae\": float(np.mean(np.abs(y_true - y_hat))),\n",
    "            \"rmse\": float(np.sqrt(np.mean((y_true - y_hat) ** 2))),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# -----------------------------\n",
    "# RUN BASELINE\n",
    "# -----------------------------\n",
    "baseline_df = pd.concat([\n",
    "    evaluate_seasonal_naive(dfs[\"hospital_dataset.tsf\"], splits_df, \"hospital_dataset.tsf\", freq=\"monthly\"),\n",
    "    evaluate_seasonal_naive(dfs[\"tourism_monthly_dataset.tsf\"], splits_df, \"tourism_monthly_dataset.tsf\", freq=\"monthly\"),\n",
    "    evaluate_seasonal_naive(dfs[\"electricity_weekly_dataset.tsf\"], splits_df, \"electricity_weekly_dataset.tsf\", freq=\"weekly\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "summary = (\n",
    "    baseline_df\n",
    "    .groupby([\"dataset\", \"horizon\"], as_index=False)\n",
    "    .agg(MAE=(\"mae\", \"mean\"), RMSE=(\"rmse\", \"mean\"))\n",
    ")\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"SEASONAL NAIVE BASELINE RESULTS\")\n",
    "print(\"=\"*90)\n",
    "print(summary)\n",
    "\n",
    "print(\"\\nRows evaluated:\", len(baseline_df))\n",
    "print(\"Any NaNs in metrics:\", baseline_df[[\"mae\", \"rmse\"]].isna().any().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d237a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aarav\\anaconda3\\envs\\mp3env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital ETS fits: 15340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hospital ETS: 100%|██████████| 307/307 [17:01<00:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "HOSPITAL ETS RESULTS\n",
      "==========================================================================================\n",
      "                dataset  horizon        MAE       RMSE\n",
      "0  hospital_dataset.tsf        6  18.586508  21.778053\n",
      "1  hospital_dataset.tsf       12  20.490773  24.421683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "N_JOBS = -1\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "SEASONAL_PERIODS = 12\n",
    "\n",
    "def ets_forecast(train_y, horizon):\n",
    "    train_y = np.asarray(train_y, dtype=float)\n",
    "    if len(train_y) < 2 * SEASONAL_PERIODS:\n",
    "        return np.repeat(train_y[-1], horizon)\n",
    "\n",
    "    model = ExponentialSmoothing(\n",
    "        train_y,\n",
    "        trend=\"add\",\n",
    "        seasonal=\"add\",\n",
    "        seasonal_periods=SEASONAL_PERIODS,\n",
    "        initialization_method=\"estimated\"\n",
    "    )\n",
    "    fit = model.fit(optimized=True)\n",
    "    return fit.forecast(horizon)\n",
    "\n",
    "def eval_one(row, grouped):\n",
    "    g = grouped[row[\"series_name\"]]\n",
    "\n",
    "    train = g[g[\"timestamp\"] <= row[\"train_end\"]]\n",
    "    test  = g[(g[\"timestamp\"] >= row[\"test_start\"]) & (g[\"timestamp\"] <= row[\"test_end\"])]\n",
    "\n",
    "    y_true = test[\"y\"].values\n",
    "    y_hat = ets_forecast(train[\"y\"].values, int(row[\"horizon\"]))\n",
    "\n",
    "    if len(y_true) != len(y_hat):\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"dataset\": DATASET,\n",
    "        \"horizon\": int(row[\"horizon\"]),\n",
    "        \"series_name\": row[\"series_name\"],\n",
    "        \"split_id\": int(row[\"split_id\"]),\n",
    "        \"mae\": float(np.mean(np.abs(y_true - y_hat))),\n",
    "        \"rmse\": float(np.sqrt(np.mean((y_true - y_hat) ** 2))),\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# PREP\n",
    "# -----------------------------\n",
    "df_hosp = dfs[DATASET].copy()\n",
    "df_hosp[\"timestamp\"] = pd.to_datetime(df_hosp[\"timestamp\"]).dt.tz_localize(None)\n",
    "\n",
    "grouped = {\n",
    "    s: g.sort_values(\"timestamp\")\n",
    "    for s, g in df_hosp.groupby(\"series_name\")\n",
    "}\n",
    "\n",
    "tasks = splits_df[splits_df[\"dataset\"] == DATASET].copy()\n",
    "tasks[\"train_end\"] = pd.to_datetime(tasks[\"train_end\"]).dt.tz_localize(None)\n",
    "tasks[\"test_start\"] = pd.to_datetime(tasks[\"test_start\"]).dt.tz_localize(None)\n",
    "tasks[\"test_end\"] = pd.to_datetime(tasks[\"test_end\"]).dt.tz_localize(None)\n",
    "\n",
    "print(\"Hospital ETS fits:\", len(tasks))\n",
    "\n",
    "# -----------------------------\n",
    "# RUN\n",
    "# -----------------------------\n",
    "results = []\n",
    "for start in tqdm(range(0, len(tasks), BATCH_SIZE), desc=\"Hospital ETS\"):\n",
    "    chunk = tasks.iloc[start:start+BATCH_SIZE]\n",
    "    out = Parallel(n_jobs=N_JOBS)(\n",
    "        delayed(eval_one)(row, grouped) for _, row in chunk.iterrows()\n",
    "    )\n",
    "    results.extend([r for r in out if r is not None])\n",
    "\n",
    "ets_hospital_df = pd.DataFrame(results)\n",
    "\n",
    "ets_hospital_summary = (\n",
    "    ets_hospital_df\n",
    "    .groupby([\"dataset\", \"horizon\"], as_index=False)\n",
    "    .agg(MAE=(\"mae\", \"mean\"), RMSE=(\"rmse\", \"mean\"))\n",
    ")\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"HOSPITAL ETS RESULTS\")\n",
    "print(\"=\"*90)\n",
    "print(ets_hospital_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63513e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Horizon 6: train=(430287, 10), test=(50622, 10)\n",
      "\n",
      "Horizon 12: train=(331344, 10), test=(82836, 10)\n",
      "==========================================================================================\n",
      "HOSPITAL ML (GLOBAL, FAST, CLEAN)\n",
      "==========================================================================================\n",
      "                dataset  horizon                  model        MAE       RMSE\n",
      "0  hospital_dataset.tsf        6  LightGBM (global p50)  17.674858  57.376329\n",
      "1  hospital_dataset.tsf       12  LightGBM (global p50)  18.052381  59.459905\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LIGHTGBM_VERBOSE\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG (LOCKED)\n",
    "# -----------------------------\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "HORIZONS = [6, 12]\n",
    "LAGS = [1, 3, 6, 12]\n",
    "ROLLS = [3, 6, 12]\n",
    "QUANTILES = [0.1, 0.5, 0.9]\n",
    "\n",
    "# -----------------------------\n",
    "# FEATURE ENGINEERING\n",
    "# -----------------------------\n",
    "df = dfs[DATASET].copy()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).dt.tz_localize(None)\n",
    "df = df.sort_values([\"series_name\", \"timestamp\"])\n",
    "df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "\n",
    "for lag in LAGS:\n",
    "    df[f\"lag_{lag}\"] = df.groupby(\"series_name\")[\"y\"].shift(lag)\n",
    "\n",
    "for r in ROLLS:\n",
    "    df[f\"roll_mean_{r}\"] = df.groupby(\"series_name\")[\"y\"].shift(1).rolling(r).mean()\n",
    "    df[f\"roll_std_{r}\"]  = df.groupby(\"series_name\")[\"y\"].shift(1).rolling(r).std()\n",
    "\n",
    "feature_cols = [c for c in df.columns if c.startswith((\"lag_\", \"roll_\"))]\n",
    "\n",
    "# -----------------------------\n",
    "# BUILD GLOBAL TRAIN / TEST SETS\n",
    "# -----------------------------\n",
    "def build_global_sets(horizon):\n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    splits = splits_df[\n",
    "        (splits_df[\"dataset\"] == DATASET) &\n",
    "        (splits_df[\"horizon\"] == horizon)\n",
    "    ]\n",
    "\n",
    "    for _, s in splits.iterrows():\n",
    "        g = df[df[\"series_name\"] == s[\"series_name\"]]\n",
    "\n",
    "        train = g[g[\"timestamp\"] <= s[\"train_end\"]].dropna(subset=feature_cols)\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) &\n",
    "                  (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "\n",
    "        if len(train) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        X_train.append(train[feature_cols])\n",
    "        y_train.append(train[\"y\"])\n",
    "\n",
    "        X_test.append(test[feature_cols])\n",
    "        y_test.append(test[\"y\"])\n",
    "\n",
    "    return (\n",
    "        pd.concat(X_train, ignore_index=True),\n",
    "        pd.concat(y_train, ignore_index=True),\n",
    "        pd.concat(X_test, ignore_index=True),\n",
    "        pd.concat(y_test, ignore_index=True)\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN GLOBAL MODELS\n",
    "# -----------------------------\n",
    "results = []\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    Xtr, ytr, Xte, yte = build_global_sets(horizon)\n",
    "\n",
    "    print(f\"\\nHorizon {horizon}: train={Xtr.shape}, test={Xte.shape}\")\n",
    "\n",
    "    for q in QUANTILES:\n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective=\"quantile\",\n",
    "            alpha=q,\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        )\n",
    "\n",
    "        model.fit(Xtr, ytr)\n",
    "        preds = model.predict(Xte)\n",
    "\n",
    "        if q == 0.5:\n",
    "            mae = mean_absolute_error(yte, preds)\n",
    "            mse = mean_squared_error(yte, preds)\n",
    "            rmse = float(np.sqrt(mse))\n",
    "            results.append({\n",
    "                \"dataset\": DATASET,\n",
    "                \"horizon\": horizon,\n",
    "                \"model\": \"LightGBM (global p50)\",\n",
    "                \"MAE\": float(mae),\n",
    "                \"RMSE\": rmse\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"HOSPITAL ML (GLOBAL, FAST, CLEAN)\")\n",
    "print(\"=\"*90)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d653e390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_true stats (h=6)\n",
      "count: 50622\n",
      "min/median/max: 1.0 40.0 12090.0\n",
      "p90/p95/p99: 659.0 1253.0 3862.0\n",
      "\n",
      "y_pred stats (h=6)\n",
      "count: 50622\n",
      "min/median/max: 5.448407845116466 40.06192431443854 11060.372240075365\n",
      "p90/p95/p99: 663.9669210209174 1234.3124054914492 3916.482745301505\n",
      "\n",
      "|error| stats (h=6)\n",
      "count: 50622\n",
      "min/median/max: 0.00012116444123577708 5.6394890137455995 1590.8779229571255\n",
      "p90/p95/p99: 35.86512907157753 65.14987818461168 206.426182731866\n",
      "\n",
      "MAE=17.675  RMSE=57.376\n",
      "\n",
      "Top 10 worst errors:\n",
      "   y_true        y_pred      abs_err\n",
      "0    9407   7816.122077  1590.877923\n",
      "1    9407   7816.122077  1590.877923\n",
      "2    8899   7311.957456  1587.042544\n",
      "3    8899   7311.957456  1587.042544\n",
      "4    6846   8337.593563  1491.593563\n",
      "5   10154   8765.282527  1388.717473\n",
      "6   12090  10867.136985  1222.863015\n",
      "7   12090  10867.136985  1222.863015\n",
      "8    6357   7487.833060  1130.833060\n",
      "9    6357   7487.833060  1130.833060\n",
      "\n",
      "y_true stats (h=12)\n",
      "count: 82836\n",
      "min/median/max: 1.0 40.0 12090.0\n",
      "p90/p95/p99: 659.0 1253.0 3860.0\n",
      "\n",
      "y_pred stats (h=12)\n",
      "count: 82836\n",
      "min/median/max: 5.154173679204807 40.15419595606351 10941.887202268037\n",
      "p90/p95/p99: 664.1143648959521 1240.9435922651028 3758.6501293931\n",
      "\n",
      "|error| stats (h=12)\n",
      "count: 82836\n",
      "min/median/max: 0.00016173766442051374 5.715483614532086 2210.059515698429\n",
      "p90/p95/p99: 36.89308633729884 66.00070117138307 221.37345519676504\n",
      "\n",
      "MAE=18.052  RMSE=59.460\n",
      "\n",
      "Top 10 worst errors:\n",
      "   y_true       y_pred      abs_err\n",
      "0    9407  7196.940484  2210.059516\n",
      "1    9407  7196.940484  2210.059516\n",
      "2    9407  7196.940484  2210.059516\n",
      "3    9407  7196.940484  2210.059516\n",
      "4    8899  6913.067702  1985.932298\n",
      "5    8899  6913.067702  1985.932298\n",
      "6    8899  6913.067702  1985.932298\n",
      "7    8899  6913.067702  1985.932298\n",
      "8   10154  8647.313203  1506.686797\n",
      "9    5625  7044.434198  1419.434198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Rebuild test set for each horizon (same as training code)\n",
    "def build_global_sets_only_test(horizon):\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    splits = splits_df[\n",
    "        (splits_df[\"dataset\"] == \"hospital_dataset.tsf\") &\n",
    "        (splits_df[\"horizon\"] == horizon)\n",
    "    ]\n",
    "\n",
    "    for _, s in splits.iterrows():\n",
    "        g = df[df[\"series_name\"] == s[\"series_name\"]]\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) &\n",
    "                  (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "        if len(test) == 0:\n",
    "            continue\n",
    "        X_test.append(test[feature_cols])\n",
    "        y_test.append(test[\"y\"])\n",
    "\n",
    "    return pd.concat(X_test, ignore_index=True), pd.concat(y_test, ignore_index=True)\n",
    "\n",
    "def quick_stats(arr, name):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"count:\", len(arr))\n",
    "    print(\"min/median/max:\", np.min(arr), np.median(arr), np.max(arr))\n",
    "    print(\"p90/p95/p99:\", np.percentile(arr, 90), np.percentile(arr, 95), np.percentile(arr, 99))\n",
    "\n",
    "for horizon in [6, 12]:\n",
    "    Xte, yte = build_global_sets_only_test(horizon)\n",
    "    quick_stats(yte.values, f\"y_true stats (h={horizon})\")\n",
    "\n",
    "    # Refit p50 model quickly (same params as before) and get preds\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "    Xtr, ytr, _, _ = build_global_sets(horizon)\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"quantile\",\n",
    "        alpha=0.5,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    model.fit(Xtr, ytr)\n",
    "    preds = model.predict(Xte)\n",
    "\n",
    "    quick_stats(preds, f\"y_pred stats (h={horizon})\")\n",
    "\n",
    "    abs_err = np.abs(yte.values - preds)\n",
    "    quick_stats(abs_err, f\"|error| stats (h={horizon})\")\n",
    "\n",
    "    mae = mean_absolute_error(yte, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(yte, preds))\n",
    "    print(f\"\\nMAE={mae:.3f}  RMSE={rmse:.3f}\")\n",
    "\n",
    "    # show top 10 worst errors\n",
    "    worst_idx = np.argsort(abs_err)[-10:][::-1]\n",
    "    worst_df = pd.DataFrame({\n",
    "        \"y_true\": yte.values[worst_idx],\n",
    "        \"y_pred\": preds[worst_idx],\n",
    "        \"abs_err\": abs_err[worst_idx]\n",
    "    })\n",
    "    print(\"\\nTop 10 worst errors:\")\n",
    "    print(worst_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615cd885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Horizon 6: train=(430287, 10), test=(50622, 10)\n",
      "\n",
      "Horizon 12: train=(331344, 10), test=(82836, 10)\n",
      "==========================================================================================\n",
      "HOSPITAL ML (GLOBAL, LOG TARGET)\n",
      "==========================================================================================\n",
      "                dataset  horizon                              model  \\\n",
      "0  hospital_dataset.tsf        6  LightGBM (global p50, log target)   \n",
      "1  hospital_dataset.tsf       12  LightGBM (global p50, log target)   \n",
      "\n",
      "         MAE       RMSE  \n",
      "0  17.340464  55.842261  \n",
      "1  17.978900  60.299794  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "HORIZONS = [6, 12]\n",
    "\n",
    "results = []\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    Xtr, ytr, Xte, yte = build_global_sets(horizon)\n",
    "\n",
    "    # log-transform target\n",
    "    ytr_log = np.log1p(ytr)\n",
    "\n",
    "    print(f\"\\nHorizon {horizon}: train={Xtr.shape}, test={Xte.shape}\")\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective=\"quantile\",\n",
    "        alpha=0.5,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    model.fit(Xtr, ytr_log)\n",
    "\n",
    "    # predict and invert\n",
    "    preds_log = model.predict(Xte)\n",
    "    preds = np.expm1(preds_log)\n",
    "\n",
    "    mae = mean_absolute_error(yte, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(yte, preds))\n",
    "\n",
    "    results.append({\n",
    "        \"dataset\": DATASET,\n",
    "        \"horizon\": horizon,\n",
    "        \"model\": \"LightGBM (global p50, log target)\",\n",
    "        \"MAE\": float(mae),\n",
    "        \"RMSE\": float(rmse)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"HOSPITAL ML (GLOBAL, LOG TARGET)\")\n",
    "print(\"=\" * 90)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f2f7441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H6 | small  | train=(149787, 10) test=(17622, 10)\n",
      "H6 | medium | train=(134079, 10) test=(15774, 10)\n",
      "H6 | large  | train=(146421, 10) test=(17226, 10)\n",
      "H12 | small  | train=(115344, 10) test=(28836, 10)\n",
      "H12 | medium | train=(103248, 10) test=(25812, 10)\n",
      "H12 | large  | train=(112752, 10) test=(28188, 10)\n",
      "====================================================================================================\n",
      "SEGMENTED GLOBAL LIGHTGBM — HOSPITAL\n",
      "====================================================================================================\n",
      "                dataset  horizon  bucket  \\\n",
      "2  hospital_dataset.tsf        6   large   \n",
      "1  hospital_dataset.tsf        6  medium   \n",
      "0  hospital_dataset.tsf        6   small   \n",
      "5  hospital_dataset.tsf       12   large   \n",
      "4  hospital_dataset.tsf       12  medium   \n",
      "3  hospital_dataset.tsf       12   small   \n",
      "\n",
      "                                     model        MAE       RMSE  \n",
      "2  LightGBM (segmented global, log target)  38.948141  89.263097  \n",
      "1  LightGBM (segmented global, log target)   6.252343   8.555698  \n",
      "0  LightGBM (segmented global, log target)   3.622809   4.793891  \n",
      "5  LightGBM (segmented global, log target)  39.824063  89.118869  \n",
      "4  LightGBM (segmented global, log target)   6.397392   8.810318  \n",
      "3  LightGBM (segmented global, log target)   3.715300   4.926587  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "HORIZONS = [6, 12]\n",
    "\n",
    "# feature config (must match your earlier global model)\n",
    "LAGS  = [1, 3, 6, 12]\n",
    "ROLLS = [3, 6, 12]\n",
    "\n",
    "# -----------------------------\n",
    "# Load + tz-fix\n",
    "# -----------------------------\n",
    "df = dfs[DATASET].copy()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).dt.tz_localize(None)\n",
    "df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "df = df.sort_values([\"series_name\", \"timestamp\"])\n",
    "\n",
    "spl = splits_df[splits_df[\"dataset\"] == DATASET].copy()\n",
    "for c in [\"train_end\", \"test_start\", \"test_end\"]:\n",
    "    spl[c] = pd.to_datetime(spl[c]).dt.tz_localize(None)\n",
    "\n",
    "# -----------------------------\n",
    "# Build features (GUARANTEED)\n",
    "# -----------------------------\n",
    "for lag in LAGS:\n",
    "    df[f\"lag_{lag}\"] = df.groupby(\"series_name\")[\"y\"].shift(lag)\n",
    "\n",
    "for r in ROLLS:\n",
    "    df[f\"roll_mean_{r}\"] = df.groupby(\"series_name\")[\"y\"].shift(1).rolling(r).mean()\n",
    "    df[f\"roll_std_{r}\"]  = df.groupby(\"series_name\")[\"y\"].shift(1).rolling(r).std()\n",
    "\n",
    "feature_cols = [c for c in df.columns if c.startswith((\"lag_\", \"roll_\"))]\n",
    "\n",
    "# sanity\n",
    "missing_feats = [c for c in [f\"lag_{x}\" for x in LAGS] + \n",
    "                 [f\"roll_mean_{r}\" for r in ROLLS] + [f\"roll_std_{r}\" for r in ROLLS]\n",
    "                 if c not in df.columns]\n",
    "if missing_feats:\n",
    "    raise RuntimeError(f\"Feature build failed, missing: {missing_feats}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Bucket by TRAIN history only\n",
    "# -----------------------------\n",
    "train_cutoff = spl[\"train_end\"].min()\n",
    "train_hist = df[df[\"timestamp\"] <= train_cutoff]\n",
    "\n",
    "series_median = train_hist.groupby(\"series_name\")[\"y\"].median()\n",
    "q1, q2 = series_median.quantile([0.33, 0.66])\n",
    "\n",
    "def size_bucket(x):\n",
    "    if x <= q1:\n",
    "        return \"small\"\n",
    "    elif x <= q2:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "series_bucket = series_median.apply(size_bucket)\n",
    "df[\"bucket\"] = df[\"series_name\"].map(series_bucket)\n",
    "\n",
    "# -----------------------------\n",
    "# Build global train/test per bucket\n",
    "# -----------------------------\n",
    "def build_bucket_sets(horizon, bucket):\n",
    "    Xtr, ytr, Xte, yte = [], [], [], []\n",
    "    splits_h = spl[spl[\"horizon\"] == horizon]\n",
    "\n",
    "    for _, s in splits_h.iterrows():\n",
    "        g = df[(df[\"series_name\"] == s[\"series_name\"]) & (df[\"bucket\"] == bucket)]\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        train = g[g[\"timestamp\"] <= s[\"train_end\"]].dropna(subset=feature_cols)\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) &\n",
    "                  (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "\n",
    "        if len(train) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        Xtr.append(train[feature_cols]); ytr.append(train[\"y\"])\n",
    "        Xte.append(test[feature_cols]);  yte.append(test[\"y\"])\n",
    "\n",
    "    if not Xtr:\n",
    "        return None\n",
    "\n",
    "    return (\n",
    "        pd.concat(Xtr, ignore_index=True),\n",
    "        pd.concat(ytr, ignore_index=True),\n",
    "        pd.concat(Xte, ignore_index=True),\n",
    "        pd.concat(yte, ignore_index=True),\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# Train 1 model per (horizon, bucket)\n",
    "# -----------------------------\n",
    "results = []\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    for bucket in [\"small\", \"medium\", \"large\"]:\n",
    "        data = build_bucket_sets(horizon, bucket)\n",
    "        if data is None:\n",
    "            print(f\"H{horizon} | {bucket:<6} | SKIP (no data)\")\n",
    "            continue\n",
    "\n",
    "        Xtr, ytr, Xte, yte = data\n",
    "        ytr_log = np.log1p(ytr)  # heavy-tail handling\n",
    "\n",
    "        print(f\"H{horizon} | {bucket:<6} | train={Xtr.shape} test={Xte.shape}\")\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective=\"quantile\",\n",
    "            alpha=0.5,\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        )\n",
    "\n",
    "        model.fit(Xtr, ytr_log)\n",
    "        preds = np.expm1(model.predict(Xte))\n",
    "\n",
    "        mae = mean_absolute_error(yte, preds)\n",
    "        rmse = np.sqrt(mean_squared_error(yte, preds))\n",
    "\n",
    "        results.append({\n",
    "            \"dataset\": DATASET,\n",
    "            \"horizon\": horizon,\n",
    "            \"bucket\": bucket,\n",
    "            \"model\": \"LightGBM (segmented global, log target)\",\n",
    "            \"MAE\": float(mae),\n",
    "            \"RMSE\": float(rmse)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values([\"horizon\", \"bucket\"])\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"SEGMENTED GLOBAL LIGHTGBM — HOSPITAL\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05754f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H6 | small  | train=(149787, 10) test=(17622, 10)\n",
      "H6 | medium | train=(134079, 10) test=(15774, 10)\n",
      "H6 | large  | train=(146421, 10) test=(17226, 10)\n",
      "H12 | small  | train=(115344, 10) test=(28836, 10)\n",
      "H12 | medium | train=(103248, 10) test=(25812, 10)\n",
      "H12 | large  | train=(112752, 10) test=(28188, 10)\n",
      "\n",
      "====================================================================================================\n",
      "SEGMENTED GLOBAL LIGHTGBM — BUCKET METRICS\n",
      "====================================================================================================\n",
      "                dataset  horizon  bucket  \\\n",
      "0  hospital_dataset.tsf        6   large   \n",
      "1  hospital_dataset.tsf        6  medium   \n",
      "2  hospital_dataset.tsf        6   small   \n",
      "3  hospital_dataset.tsf       12   large   \n",
      "4  hospital_dataset.tsf       12  medium   \n",
      "5  hospital_dataset.tsf       12   small   \n",
      "\n",
      "                                     model        MAE       RMSE  \n",
      "0  LightGBM (segmented global, log target)  38.948141  89.263097  \n",
      "1  LightGBM (segmented global, log target)   6.252343   8.555698  \n",
      "2  LightGBM (segmented global, log target)   3.622809   4.793891  \n",
      "3  LightGBM (segmented global, log target)  39.824063  89.118869  \n",
      "4  LightGBM (segmented global, log target)   6.397392   8.810318  \n",
      "5  LightGBM (segmented global, log target)   3.715300   4.926587  \n",
      "\n",
      "====================================================================================================\n",
      "SEGMENTED GLOBAL LIGHTGBM — WEIGHTED OVERALL METRICS\n",
      "====================================================================================================\n",
      "                dataset  horizon                                  model  \\\n",
      "0  hospital_dataset.tsf        6  LightGBM (segmented global, weighted)   \n",
      "1  hospital_dataset.tsf       12  LightGBM (segmented global, weighted)   \n",
      "\n",
      "   Weighted_MAE  Weighted_RMSE  Total_Test_Rows  \n",
      "0     16.462927      52.365838            50622  \n",
      "1     16.838386      52.299647            82836  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# =============================\n",
    "# SEGMENTED GLOBAL LIGHTGBM — HOSPITAL (END-TO-END)\n",
    "# - tz-safe\n",
    "# - builds lag/rolling features\n",
    "# - buckets series by training-median y (small/medium/large)\n",
    "# - trains 1 global model per (horizon, bucket) on log1p(y)\n",
    "# - reports bucket metrics + weighted overall metrics\n",
    "# =============================\n",
    "\n",
    "DATASET = \"hospital_dataset.tsf\"\n",
    "HORIZONS = [6, 12]\n",
    "\n",
    "LAGS  = [1, 3, 6, 12]\n",
    "ROLLS = [3, 6, 12]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load data + tz-fix\n",
    "# -----------------------------\n",
    "df = dfs[DATASET].copy()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).dt.tz_localize(None)\n",
    "df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "df = df.sort_values([\"series_name\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "spl = splits_df[splits_df[\"dataset\"] == DATASET].copy()\n",
    "for c in [\"train_end\", \"test_start\", \"test_end\"]:\n",
    "    spl[c] = pd.to_datetime(spl[c]).dt.tz_localize(None)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build features (guaranteed)\n",
    "# -----------------------------\n",
    "for lag in LAGS:\n",
    "    df[f\"lag_{lag}\"] = df.groupby(\"series_name\")[\"y\"].shift(lag)\n",
    "\n",
    "for r in ROLLS:\n",
    "    # IMPORTANT: shift(1) ensures rolling uses ONLY past values\n",
    "    df[f\"roll_mean_{r}\"] = (\n",
    "        df.groupby(\"series_name\")[\"y\"]\n",
    "          .shift(1)\n",
    "          .rolling(r)\n",
    "          .mean()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[f\"roll_std_{r}\"] = (\n",
    "        df.groupby(\"series_name\")[\"y\"]\n",
    "          .shift(1)\n",
    "          .rolling(r)\n",
    "          .std()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "feature_cols = [c for c in df.columns if c.startswith((\"lag_\", \"roll_\"))]\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Bucket series by TRAIN history only\n",
    "# -----------------------------\n",
    "train_cutoff = spl[\"train_end\"].min()\n",
    "train_hist = df[df[\"timestamp\"] <= train_cutoff]\n",
    "\n",
    "series_median = train_hist.groupby(\"series_name\")[\"y\"].median()\n",
    "q1, q2 = series_median.quantile([0.33, 0.66])\n",
    "\n",
    "def size_bucket(v):\n",
    "    if v <= q1:\n",
    "        return \"small\"\n",
    "    elif v <= q2:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "series_bucket = series_median.apply(size_bucket)\n",
    "df[\"bucket\"] = df[\"series_name\"].map(series_bucket)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Build global train/test per bucket for a horizon\n",
    "# -----------------------------\n",
    "def build_bucket_sets(horizon, bucket):\n",
    "    Xtr, ytr, Xte, yte = [], [], [], []\n",
    "\n",
    "    splits_h = spl[spl[\"horizon\"] == horizon]\n",
    "    for _, s in splits_h.iterrows():\n",
    "        g = df[(df[\"series_name\"] == s[\"series_name\"]) & (df[\"bucket\"] == bucket)]\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        train = g[g[\"timestamp\"] <= s[\"train_end\"]].dropna(subset=feature_cols)\n",
    "        test  = g[(g[\"timestamp\"] >= s[\"test_start\"]) & (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "\n",
    "        if len(train) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        Xtr.append(train[feature_cols]); ytr.append(train[\"y\"])\n",
    "        Xte.append(test[feature_cols]);  yte.append(test[\"y\"])\n",
    "\n",
    "    if not Xtr:\n",
    "        return None\n",
    "\n",
    "    return (\n",
    "        pd.concat(Xtr, ignore_index=True),\n",
    "        pd.concat(ytr, ignore_index=True),\n",
    "        pd.concat(Xte, ignore_index=True),\n",
    "        pd.concat(yte, ignore_index=True),\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Train segmented global models + compute metrics\n",
    "# -----------------------------\n",
    "bucket_metrics = []\n",
    "bucket_counts = []  # store test row counts for weighted aggregation\n",
    "models = {}         # (horizon, bucket) -> fitted model (optional)\n",
    "\n",
    "for horizon in HORIZONS:\n",
    "    for bucket in [\"small\", \"medium\", \"large\"]:\n",
    "        data = build_bucket_sets(horizon, bucket)\n",
    "        if data is None:\n",
    "            print(f\"H{horizon} | {bucket:<6} | SKIP (no data)\")\n",
    "            continue\n",
    "\n",
    "        Xtr, ytr, Xte, yte = data\n",
    "        n_test = len(yte)\n",
    "\n",
    "        print(f\"H{horizon} | {bucket:<6} | train={Xtr.shape} test={Xte.shape}\")\n",
    "\n",
    "        # log target for heavy tail\n",
    "        ytr_log = np.log1p(ytr)\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective=\"quantile\",\n",
    "            alpha=0.5,\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        )\n",
    "        model.fit(Xtr, ytr_log)\n",
    "        preds = np.expm1(model.predict(Xte))\n",
    "\n",
    "        models[(horizon, bucket)] = model\n",
    "\n",
    "        mae_val = float(mean_absolute_error(yte, preds))\n",
    "        rmse_val = rmse(yte, preds)\n",
    "\n",
    "        bucket_metrics.append({\n",
    "            \"dataset\": DATASET,\n",
    "            \"horizon\": horizon,\n",
    "            \"bucket\": bucket,\n",
    "            \"model\": \"LightGBM (segmented global, log target)\",\n",
    "            \"MAE\": mae_val,\n",
    "            \"RMSE\": rmse_val\n",
    "        })\n",
    "        bucket_counts.append({\n",
    "            \"horizon\": horizon,\n",
    "            \"bucket\": bucket,\n",
    "            \"n_test\": int(n_test)\n",
    "        })\n",
    "\n",
    "bucket_df = pd.DataFrame(bucket_metrics).sort_values([\"horizon\", \"bucket\"]).reset_index(drop=True)\n",
    "counts_df = pd.DataFrame(bucket_counts)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SEGMENTED GLOBAL LIGHTGBM — BUCKET METRICS\")\n",
    "print(\"=\" * 100)\n",
    "print(bucket_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Weighted overall metrics (per horizon)\n",
    "# Weighted RMSE uses MSE aggregation:\n",
    "#   RMSE_weighted = sqrt( sum(n_i * RMSE_i^2) / sum(n_i) )\n",
    "# -----------------------------\n",
    "weighted_rows = []\n",
    "for horizon in HORIZONS:\n",
    "    sub = bucket_df[bucket_df[\"horizon\"] == horizon].merge(\n",
    "        counts_df[counts_df[\"horizon\"] == horizon],\n",
    "        on=[\"horizon\", \"bucket\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    total_n = sub[\"n_test\"].sum()\n",
    "\n",
    "    w_mae = (sub[\"MAE\"] * sub[\"n_test\"]).sum() / total_n\n",
    "    w_rmse = float(np.sqrt(((sub[\"RMSE\"] ** 2) * sub[\"n_test\"]).sum() / total_n))\n",
    "\n",
    "    weighted_rows.append({\n",
    "        \"dataset\": DATASET,\n",
    "        \"horizon\": horizon,\n",
    "        \"model\": \"LightGBM (segmented global, weighted)\",\n",
    "        \"Weighted_MAE\": float(w_mae),\n",
    "        \"Weighted_RMSE\": float(w_rmse),\n",
    "        \"Total_Test_Rows\": int(total_n)\n",
    "    })\n",
    "\n",
    "weighted_df = pd.DataFrame(weighted_rows).sort_values(\"horizon\").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SEGMENTED GLOBAL LIGHTGBM — WEIGHTED OVERALL METRICS\")\n",
    "print(\"=\" * 100)\n",
    "print(weighted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6616bdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SHAP TreeExplainer (check_additivity=False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 9842/10000 [00:52<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H6_small.csv | rows explained=10000 | background=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9923/10000 [00:55<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H6_medium.csv | rows explained=10000 | background=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9865/10000 [00:50<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H6_large.csv | rows explained=10000 | background=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9925/10000 [00:45<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H12_small.csv | rows explained=10000 | background=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 9978/10000 [00:55<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H12_medium.csv | rows explained=10000 | background=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 9999/10000 [00:56<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./artifacts_interpretability\\shap_importance_hospital_dataset.tsf_H12_large.csv | rows explained=10000 | background=2000\n",
      "\n",
      "====================================================================================================\n",
      "TOP SHAP FEATURES (mean |SHAP|) — per horizon & bucket\n",
      "====================================================================================================\n",
      "         feature  mean_abs_shap               dataset  horizon  bucket\n",
      "0          lag_1       0.367885  hospital_dataset.tsf        6   large\n",
      "1    roll_mean_3       0.305724  hospital_dataset.tsf        6   large\n",
      "2         lag_12       0.111043  hospital_dataset.tsf        6   large\n",
      "3   roll_mean_12       0.105898  hospital_dataset.tsf        6   large\n",
      "4    roll_mean_6       0.051217  hospital_dataset.tsf        6   large\n",
      "5          lag_3       0.015017  hospital_dataset.tsf        6   large\n",
      "6          lag_6       0.013568  hospital_dataset.tsf        6   large\n",
      "7    roll_std_12       0.004639  hospital_dataset.tsf        6   large\n",
      "8     roll_std_6       0.004469  hospital_dataset.tsf        6   large\n",
      "9     roll_std_3       0.004287  hospital_dataset.tsf        6   large\n",
      "10   roll_mean_3       0.131671  hospital_dataset.tsf        6  medium\n",
      "11         lag_1       0.082823  hospital_dataset.tsf        6  medium\n",
      "12  roll_mean_12       0.077106  hospital_dataset.tsf        6  medium\n",
      "13   roll_mean_6       0.025473  hospital_dataset.tsf        6  medium\n",
      "14        lag_12       0.022395  hospital_dataset.tsf        6  medium\n",
      "15         lag_6       0.014659  hospital_dataset.tsf        6  medium\n",
      "16         lag_3       0.012048  hospital_dataset.tsf        6  medium\n",
      "17   roll_std_12       0.004902  hospital_dataset.tsf        6  medium\n",
      "18    roll_std_6       0.004008  hospital_dataset.tsf        6  medium\n",
      "19    roll_std_3       0.003664  hospital_dataset.tsf        6  medium\n",
      "20  roll_mean_12       0.101935  hospital_dataset.tsf        6   small\n",
      "21   roll_mean_3       0.080105  hospital_dataset.tsf        6   small\n",
      "22         lag_1       0.050778  hospital_dataset.tsf        6   small\n",
      "23   roll_mean_6       0.026751  hospital_dataset.tsf        6   small\n",
      "24        lag_12       0.011984  hospital_dataset.tsf        6   small\n",
      "25         lag_3       0.011913  hospital_dataset.tsf        6   small\n",
      "26   roll_std_12       0.008633  hospital_dataset.tsf        6   small\n",
      "27         lag_6       0.006373  hospital_dataset.tsf        6   small\n",
      "28    roll_std_6       0.006320  hospital_dataset.tsf        6   small\n",
      "29    roll_std_3       0.004054  hospital_dataset.tsf        6   small\n",
      "30         lag_1       0.377732  hospital_dataset.tsf       12   large\n",
      "31   roll_mean_3       0.292204  hospital_dataset.tsf       12   large\n",
      "32  roll_mean_12       0.110002  hospital_dataset.tsf       12   large\n",
      "33        lag_12       0.100166  hospital_dataset.tsf       12   large\n",
      "34   roll_mean_6       0.057261  hospital_dataset.tsf       12   large\n",
      "35         lag_3       0.016863  hospital_dataset.tsf       12   large\n",
      "36         lag_6       0.016458  hospital_dataset.tsf       12   large\n",
      "37    roll_std_3       0.006292  hospital_dataset.tsf       12   large\n",
      "38   roll_std_12       0.005890  hospital_dataset.tsf       12   large\n",
      "39    roll_std_6       0.004232  hospital_dataset.tsf       12   large\n",
      "40   roll_mean_3       0.130779  hospital_dataset.tsf       12  medium\n",
      "41         lag_1       0.087606  hospital_dataset.tsf       12  medium\n",
      "42  roll_mean_12       0.072051  hospital_dataset.tsf       12  medium\n",
      "43   roll_mean_6       0.028885  hospital_dataset.tsf       12  medium\n",
      "44        lag_12       0.023002  hospital_dataset.tsf       12  medium\n",
      "45         lag_6       0.016498  hospital_dataset.tsf       12  medium\n",
      "46         lag_3       0.011057  hospital_dataset.tsf       12  medium\n",
      "47   roll_std_12       0.005568  hospital_dataset.tsf       12  medium\n",
      "48    roll_std_6       0.004254  hospital_dataset.tsf       12  medium\n",
      "49    roll_std_3       0.004043  hospital_dataset.tsf       12  medium\n",
      "50  roll_mean_12       0.101374  hospital_dataset.tsf       12   small\n",
      "51   roll_mean_3       0.078485  hospital_dataset.tsf       12   small\n",
      "52         lag_1       0.055917  hospital_dataset.tsf       12   small\n",
      "53   roll_mean_6       0.025237  hospital_dataset.tsf       12   small\n",
      "54   roll_std_12       0.010549  hospital_dataset.tsf       12   small\n",
      "55         lag_3       0.009738  hospital_dataset.tsf       12   small\n",
      "56        lag_12       0.009482  hospital_dataset.tsf       12   small\n",
      "57         lag_6       0.008869  hospital_dataset.tsf       12   small\n",
      "58    roll_std_6       0.005647  hospital_dataset.tsf       12   small\n",
      "59    roll_std_3       0.004201  hospital_dataset.tsf       12   small\n",
      "\n",
      "Saved: ./artifacts_interpretability\\shap_top15_hospital_dataset.tsf.csv\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INTERPRETABILITY BLOCK (DROP-IN, FIXED FOR SHAP ADDITIVITY ERROR)\n",
    "# - sets check_additivity=False\n",
    "# - keeps everything else the same\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- REQUIRED INPUTS ----------\n",
    "req = [\"df\", \"spl\", \"feature_cols\", \"models\", \"DATASET\", \"HORIZONS\"]\n",
    "missing = [r for r in req if r not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing required variables: {missing}\\n\"\n",
    "        \"Run your segmented LightGBM training cell first (the one that creates df/spl/feature_cols/models).\"\n",
    "    )\n",
    "\n",
    "OUT_DIR = \"./artifacts_interpretability\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "MAX_BACKGROUND = 2000\n",
    "MAX_EXPLAIN    = 10000\n",
    "RANDOM_SEED    = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "def build_bucket_test_matrix(horizon: int, bucket: str):\n",
    "    Xte_list, yte_list = [], []\n",
    "    splits_h = spl[spl[\"horizon\"] == horizon]\n",
    "\n",
    "    for _, s in splits_h.iterrows():\n",
    "        g = df[(df[\"series_name\"] == s[\"series_name\"]) & (df[\"bucket\"] == bucket)]\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        test = g[(g[\"timestamp\"] >= s[\"test_start\"]) & (g[\"timestamp\"] <= s[\"test_end\"])].dropna(subset=feature_cols)\n",
    "        if len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        Xte_list.append(test[feature_cols])\n",
    "        yte_list.append(test[\"y\"])\n",
    "\n",
    "    if not Xte_list:\n",
    "        return None\n",
    "\n",
    "    Xte = pd.concat(Xte_list, ignore_index=True)\n",
    "    yte = pd.concat(yte_list, ignore_index=True)\n",
    "    return Xte, yte\n",
    "\n",
    "def sample_df(X: pd.DataFrame, max_rows: int):\n",
    "    if len(X) <= max_rows:\n",
    "        return X.reset_index(drop=True)\n",
    "    idx = rng.choice(len(X), size=max_rows, replace=False)\n",
    "    return X.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "# ---------- TRY SHAP ----------\n",
    "use_shap = True\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    use_shap = False\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "if use_shap:\n",
    "    print(\"Using SHAP TreeExplainer (check_additivity=False).\")\n",
    "    for horizon in HORIZONS:\n",
    "        for bucket in [\"small\", \"medium\", \"large\"]:\n",
    "            key = (horizon, bucket)\n",
    "            if key not in models:\n",
    "                print(f\"SKIP: no model for {key}\")\n",
    "                continue\n",
    "\n",
    "            data = build_bucket_test_matrix(horizon, bucket)\n",
    "            if data is None:\n",
    "                print(f\"SKIP: no test data for H{horizon} {bucket}\")\n",
    "                continue\n",
    "\n",
    "            Xte, _ = data\n",
    "\n",
    "            X_bg = sample_df(Xte, MAX_BACKGROUND)\n",
    "            X_ex = sample_df(Xte, MAX_EXPLAIN)\n",
    "\n",
    "            model = models[key]\n",
    "\n",
    "            # IMPORTANT FIX: disable additivity check\n",
    "            explainer = shap.TreeExplainer(model, data=X_bg, feature_perturbation=\"interventional\")\n",
    "            shap_vals = explainer.shap_values(X_ex, check_additivity=False)\n",
    "\n",
    "            imp = np.mean(np.abs(shap_vals), axis=0)\n",
    "            imp_df = pd.DataFrame({\"feature\": feature_cols, \"mean_abs_shap\": imp})\n",
    "            imp_df = imp_df.sort_values(\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "            imp_df[\"dataset\"] = DATASET\n",
    "            imp_df[\"horizon\"] = horizon\n",
    "            imp_df[\"bucket\"] = bucket\n",
    "            all_rows.append(imp_df)\n",
    "\n",
    "            out_path = os.path.join(OUT_DIR, f\"shap_importance_{DATASET}_H{horizon}_{bucket}.csv\")\n",
    "            imp_df.to_csv(out_path, index=False)\n",
    "            print(f\"Saved: {out_path} | rows explained={len(X_ex)} | background={len(X_bg)}\")\n",
    "\n",
    "    if not all_rows:\n",
    "        raise RuntimeError(\"No SHAP outputs produced (check models/test data).\")\n",
    "\n",
    "    shap_all = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    TOPK = 15\n",
    "    topk = (\n",
    "        shap_all\n",
    "        .sort_values([\"horizon\", \"bucket\", \"mean_abs_shap\"], ascending=[True, True, False])\n",
    "        .groupby([\"dataset\", \"horizon\", \"bucket\"], as_index=False)\n",
    "        .head(TOPK)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"TOP SHAP FEATURES (mean |SHAP|) — per horizon & bucket\")\n",
    "    print(\"=\" * 100)\n",
    "    print(topk)\n",
    "\n",
    "    topk_path = os.path.join(OUT_DIR, f\"shap_top{TOPK}_{DATASET}.csv\")\n",
    "    topk.to_csv(topk_path, index=False)\n",
    "    print(f\"\\nSaved: {topk_path}\")\n",
    "\n",
    "else:\n",
    "    # fallback: permutation importance\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "    print(\"SHAP not available -> using permutation importance.\")\n",
    "\n",
    "    def mae_scorer(model, X, y):\n",
    "        pred = np.expm1(model.predict(X))\n",
    "        return mean_absolute_error(y, pred)\n",
    "\n",
    "    def score_fn(est, X, y):\n",
    "        return -mae_scorer(est, X, y)\n",
    "\n",
    "    for horizon in HORIZONS:\n",
    "        for bucket in [\"small\", \"medium\", \"large\"]:\n",
    "            key = (horizon, bucket)\n",
    "            if key not in models:\n",
    "                print(f\"SKIP: no model for {key}\")\n",
    "                continue\n",
    "\n",
    "            data = build_bucket_test_matrix(horizon, bucket)\n",
    "            if data is None:\n",
    "                print(f\"SKIP: no test data for H{horizon} {bucket}\")\n",
    "                continue\n",
    "\n",
    "            Xte, yte = data\n",
    "            X_ex = sample_df(Xte, min(MAX_EXPLAIN, 5000))\n",
    "            y_ex = yte.iloc[X_ex.index].reset_index(drop=True)\n",
    "\n",
    "            model = models[key]\n",
    "\n",
    "            perm = permutation_importance(\n",
    "                model, X_ex, y_ex,\n",
    "                scoring=score_fn,\n",
    "                n_repeats=5,\n",
    "                random_state=RANDOM_SEED,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            imp_df = pd.DataFrame({\n",
    "                \"feature\": feature_cols,\n",
    "                \"mean_importance\": perm.importances_mean,\n",
    "                \"std_importance\": perm.importances_std\n",
    "            }).sort_values(\"mean_importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "            imp_df[\"dataset\"] = DATASET\n",
    "            imp_df[\"horizon\"] = horizon\n",
    "            imp_df[\"bucket\"] = bucket\n",
    "            all_rows.append(imp_df)\n",
    "\n",
    "            out_path = os.path.join(OUT_DIR, f\"perm_importance_{DATASET}_H{horizon}_{bucket}.csv\")\n",
    "            imp_df.to_csv(out_path, index=False)\n",
    "            print(f\"Saved: {out_path} | rows used={len(X_ex)}\")\n",
    "\n",
    "    perm_all = pd.concat(all_rows, ignore_index=True)\n",
    "    TOPK = 15\n",
    "    topk = (\n",
    "        perm_all\n",
    "        .sort_values([\"horizon\", \"bucket\", \"mean_importance\"], ascending=[True, True, False])\n",
    "        .groupby([\"dataset\", \"horizon\", \"bucket\"], as_index=False)\n",
    "        .head(TOPK)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"TOP PERMUTATION FEATURES — per horizon & bucket\")\n",
    "    print(\"=\" * 100)\n",
    "    print(topk)\n",
    "\n",
    "    topk_path = os.path.join(OUT_DIR, f\"perm_top{TOPK}_{DATASET}.csv\")\n",
    "    topk.to_csv(topk_path, index=False)\n",
    "    print(f\"\\nSaved: {topk_path}\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8dfd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] LLM_outputs\\baseline_summary.csv  rows=4  cols=4\n",
      "[saved] LLM_outputs\\baseline_seasonal_naive_rows.csv  rows=30,358  cols=6\n",
      "[saved] LLM_outputs\\ets_hospital_summary.csv  rows=2  cols=4\n",
      "[saved] LLM_outputs\\ets_hospital_rows.csv  rows=15,340  cols=6\n",
      "[saved] LLM_outputs\\lgbm_global_metrics.csv  rows=6  cols=6\n",
      "[saved] LLM_outputs\\lgbm_segmented_bucket_metrics.csv  rows=6  cols=6\n",
      "[saved] LLM_outputs\\lgbm_segmented_weighted_metrics.csv  rows=2  cols=6\n",
      "[saved] LLM_outputs\\interpret_shap_top_all.csv  rows=60  cols=6\n",
      "[saved] LLM_outputs\\interpret_shap_importance_all.csv  rows=60  cols=6\n",
      "[saved] LLM_outputs\\split_summary.csv  rows=4  cols=6\n",
      "[saved] LLM_outputs\\llm_packet.json\n",
      "[saved] LLM_outputs\\prompt_system.txt\n",
      "[saved] LLM_outputs\\prompt_user.txt\n",
      "[saved] LLM_outputs\\manifest.json\n",
      "\n",
      "✅ LLM packaging complete. Next step: build the LangChain/LangGraph pipeline that reads manifest.json and generates narratives.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LLM PACKAGING BLOCK (DROP-IN)\n",
    "# Saves ONLY model outputs + interpretability summaries to ./LLM_outputs\n",
    "# so an LLM (DeepSeek via LangChain/LangGraph) can narrate results later.\n",
    "#\n",
    "# Assumes you already ran:\n",
    "# - baseline_df, ets_hospital_df (optional but handled)\n",
    "# - results_df (global LGBM) (optional)\n",
    "# - bucket_df, weighted_df (segmented LGBM)  (recommended)\n",
    "# - SHAP outputs saved under ./artifacts_interpretability (your block already does this)\n",
    "# - dfs, splits_df exist\n",
    "# ============================================================\n",
    "\n",
    "import os, json, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = Path(\"./LLM_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_write_df(df: pd.DataFrame, filename: str):\n",
    "    if df is None:\n",
    "        return\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return\n",
    "    out_path = OUT_DIR / filename\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"[saved] {out_path}  rows={len(df):,}  cols={df.shape[1]}\")\n",
    "\n",
    "def _safe_write_json(obj, filename: str):\n",
    "    out_path = OUT_DIR / filename\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, default=str)\n",
    "    print(f\"[saved] {out_path}\")\n",
    "\n",
    "def _maybe_get_df(name: str):\n",
    "    return globals().get(name, None)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Save core metric tables (if present in your namespace)\n",
    "# ------------------------------------------------------------\n",
    "_safe_write_df(_maybe_get_df(\"summary\"), \"baseline_summary.csv\")  # if you reused name 'summary' later, ignore\n",
    "_safe_write_df(_maybe_get_df(\"baseline_df\"), \"baseline_seasonal_naive_rows.csv\")\n",
    "_safe_write_df(_maybe_get_df(\"ets_hospital_summary\") if \"ets_hospital_summary\" in globals() else None, \"ets_hospital_summary.csv\")\n",
    "_safe_write_df(_maybe_get_df(\"ets_hospital_df\"), \"ets_hospital_rows.csv\")\n",
    "_safe_write_df(_maybe_get_df(\"results_df\"), \"lgbm_global_metrics.csv\")       # your \"HOSPITAL ML (GLOBAL...)\" table\n",
    "_safe_write_df(_maybe_get_df(\"bucket_df\"), \"lgbm_segmented_bucket_metrics.csv\")\n",
    "_safe_write_df(_maybe_get_df(\"weighted_df\"), \"lgbm_segmented_weighted_metrics.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Save SHAP/perm summaries (reads your artifact folder)\n",
    "# ------------------------------------------------------------\n",
    "ART_DIR = Path(\"./artifacts_interpretability\")\n",
    "shap_top_files = sorted(ART_DIR.glob(\"shap_top*_*.csv\"))\n",
    "shap_imp_files = sorted(ART_DIR.glob(\"shap_importance_*.csv\"))\n",
    "perm_top_files = sorted(ART_DIR.glob(\"perm_top*_*.csv\"))\n",
    "perm_imp_files = sorted(ART_DIR.glob(\"perm_importance_*.csv\"))\n",
    "\n",
    "def _concat_csvs(files):\n",
    "    if not files:\n",
    "        return None\n",
    "    dfs_ = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            df_ = pd.read_csv(fp)\n",
    "            df_[\"source_file\"] = fp.name\n",
    "            dfs_.append(df_)\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] failed reading {fp}: {e}\")\n",
    "    if not dfs_:\n",
    "        return None\n",
    "    return pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "shap_top_all = _concat_csvs(shap_top_files)\n",
    "shap_imp_all = _concat_csvs(shap_imp_files)\n",
    "perm_top_all = _concat_csvs(perm_top_files)\n",
    "perm_imp_all = _concat_csvs(perm_imp_files)\n",
    "\n",
    "_safe_write_df(shap_top_all, \"interpret_shap_top_all.csv\")\n",
    "_safe_write_df(shap_imp_all, \"interpret_shap_importance_all.csv\")\n",
    "_safe_write_df(perm_top_all, \"interpret_perm_top_all.csv\")\n",
    "_safe_write_df(perm_imp_all, \"interpret_perm_importance_all.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Build a single compact JSON \"LLM packet\" (best for LangGraph)\n",
    "#    Keeps it small + structured (no raw full time series).\n",
    "# ------------------------------------------------------------\n",
    "packet = {}\n",
    "\n",
    "# minimal dataset metadata + split summary\n",
    "try:\n",
    "    split_summary = (\n",
    "        splits_df.groupby([\"dataset\", \"horizon\"], as_index=False)\n",
    "        .agg(\n",
    "            n_splits=(\"split_id\", \"nunique\"),\n",
    "            n_series=(\"series_name\", \"nunique\"),\n",
    "            first_train_end=(\"train_end\", \"min\"),\n",
    "            last_test_end=(\"test_end\", \"max\"),\n",
    "        )\n",
    "    )\n",
    "    packet[\"split_summary\"] = split_summary.to_dict(orient=\"records\")\n",
    "    _safe_write_df(split_summary, \"split_summary.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"[warn] split summary not saved: {e}\")\n",
    "\n",
    "# store model metric tables (if available)\n",
    "def _df_to_records(df):\n",
    "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return None\n",
    "    return df.replace({np.nan: None}).to_dict(orient=\"records\")\n",
    "\n",
    "packet[\"metrics\"] = {\n",
    "    \"seasonal_naive_rows\": None,     # deliberately not included (too big) unless you want it\n",
    "    \"seasonal_naive_summary\": _df_to_records(_maybe_get_df(\"summary\")) if isinstance(_maybe_get_df(\"summary\"), pd.DataFrame) else None,\n",
    "    \"ets_hospital_summary\": _df_to_records(_maybe_get_df(\"ets_hospital_summary\")),\n",
    "    \"lgbm_global_metrics\": _df_to_records(_maybe_get_df(\"results_df\")),\n",
    "    \"lgbm_segmented_bucket_metrics\": _df_to_records(_maybe_get_df(\"bucket_df\")),\n",
    "    \"lgbm_segmented_weighted_metrics\": _df_to_records(_maybe_get_df(\"weighted_df\")),\n",
    "}\n",
    "\n",
    "# extract a clean \"top features\" table if present\n",
    "top_features = None\n",
    "if shap_top_all is not None and not shap_top_all.empty:\n",
    "    # Normalize columns (your shap_top has: feature, mean_abs_shap, dataset, horizon, bucket)\n",
    "    cols = [c for c in [\"dataset\", \"horizon\", \"bucket\", \"feature\", \"mean_abs_shap\"] if c in shap_top_all.columns]\n",
    "    top_features = shap_top_all[cols].copy()\n",
    "    top_features = top_features.sort_values([\"dataset\",\"horizon\",\"bucket\",\"mean_abs_shap\"], ascending=[True, True, True, False])\n",
    "    packet[\"interpretability\"] = {\"method\": \"shap\", \"top_features\": top_features.to_dict(orient=\"records\")}\n",
    "elif perm_top_all is not None and not perm_top_all.empty:\n",
    "    cols = [c for c in [\"dataset\", \"horizon\", \"bucket\", \"feature\", \"mean_importance\"] if c in perm_top_all.columns]\n",
    "    top_features = perm_top_all[cols].copy()\n",
    "    top_features = top_features.sort_values([\"dataset\",\"horizon\",\"bucket\",\"mean_importance\"], ascending=[True, True, True, False])\n",
    "    packet[\"interpretability\"] = {\"method\": \"permutation\", \"top_features\": top_features.to_dict(orient=\"records\")}\n",
    "else:\n",
    "    packet[\"interpretability\"] = {\"method\": None, \"top_features\": None}\n",
    "\n",
    "_safe_write_json(packet, \"llm_packet.json\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Write prompt templates your LLM will consume (no API calls here)\n",
    "# ------------------------------------------------------------\n",
    "SYSTEM_PROMPT = \"\"\"You are an analytics assistant. You must ONLY interpret provided results.\n",
    "You must NOT forecast new values, tune models, or invent numbers.\n",
    "Use the structured JSON packet and CSV summaries as ground truth.\n",
    "\n",
    "Output format:\n",
    "1) Executive summary (5-8 bullets)\n",
    "2) Model comparison (baseline vs ETS vs ML)\n",
    "3) Segment insights (small/medium/large)\n",
    "4) Horizon insights (6 vs 12 months where available)\n",
    "5) Key drivers from interpretability (top features)\n",
    "6) Limitations + next steps\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"Interpret the attached project outputs.\n",
    "\n",
    "You are given:\n",
    "- split_summary.csv\n",
    "- lgbm_segmented_weighted_metrics.csv (if present)\n",
    "- lgbm_segmented_bucket_metrics.csv (if present)\n",
    "- ets_hospital_summary.csv (if present)\n",
    "- baseline_seasonal_naive_rows.csv and/or baseline_summary.csv (if present)\n",
    "- interpret_shap_top_all.csv (if present)\n",
    "- llm_packet.json\n",
    "\n",
    "Rules:\n",
    "- Do not hallucinate metrics; only cite what is present.\n",
    "- If something is missing, say it is missing.\n",
    "- Explain why the segmented model may outperform or underperform the global model.\n",
    "- Use interpretability results to explain *why* the model behaves as it does.\n",
    "\"\"\"\n",
    "\n",
    "(OUT_DIR / \"prompt_system.txt\").write_text(SYSTEM_PROMPT, encoding=\"utf-8\")\n",
    "(OUT_DIR / \"prompt_user.txt\").write_text(USER_PROMPT, encoding=\"utf-8\")\n",
    "print(f\"[saved] {OUT_DIR / 'prompt_system.txt'}\")\n",
    "print(f\"[saved] {OUT_DIR / 'prompt_user.txt'}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Create a simple manifest for LangGraph ingestion\n",
    "# ------------------------------------------------------------\n",
    "manifest = {\n",
    "    \"llm_packet\": str(OUT_DIR / \"llm_packet.json\"),\n",
    "    \"tables\": {\n",
    "        \"split_summary\": str(OUT_DIR / \"split_summary.csv\") if (OUT_DIR / \"split_summary.csv\").exists() else None,\n",
    "        \"baseline_summary\": str(OUT_DIR / \"baseline_summary.csv\") if (OUT_DIR / \"baseline_summary.csv\").exists() else None,\n",
    "        \"ets_hospital_summary\": str(OUT_DIR / \"ets_hospital_summary.csv\") if (OUT_DIR / \"ets_hospital_summary.csv\").exists() else None,\n",
    "        \"lgbm_global_metrics\": str(OUT_DIR / \"lgbm_global_metrics.csv\") if (OUT_DIR / \"lgbm_global_metrics.csv\").exists() else None,\n",
    "        \"lgbm_segmented_bucket_metrics\": str(OUT_DIR / \"lgbm_segmented_bucket_metrics.csv\") if (OUT_DIR / \"lgbm_segmented_bucket_metrics.csv\").exists() else None,\n",
    "        \"lgbm_segmented_weighted_metrics\": str(OUT_DIR / \"lgbm_segmented_weighted_metrics.csv\") if (OUT_DIR / \"lgbm_segmented_weighted_metrics.csv\").exists() else None,\n",
    "        \"interpret_shap_top_all\": str(OUT_DIR / \"interpret_shap_top_all.csv\") if (OUT_DIR / \"interpret_shap_top_all.csv\").exists() else None,\n",
    "    },\n",
    "    \"prompts\": {\n",
    "        \"system\": str(OUT_DIR / \"prompt_system.txt\"),\n",
    "        \"user\": str(OUT_DIR / \"prompt_user.txt\"),\n",
    "    }\n",
    "}\n",
    "_safe_write_json(manifest, \"manifest.json\")\n",
    "\n",
    "print(\"\\n✅ LLM packaging complete. Next step: build the LangChain/LangGraph pipeline that reads manifest.json and generates narratives.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8988cf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING CONTEXT FOR DEEPSEEK...\n",
      "\n",
      "[Saved] baseline_metrics.csv\n",
      "[Saved] ets_metrics.csv\n",
      "[Saved] ml_global_metrics.csv\n",
      "[Saved] ml_segmented_buckets.csv\n",
      "[Saved] ml_segmented_weighted.csv\n",
      "[Saved] shap_top_drivers.csv\n",
      "\n",
      "✅ Data successfully saved to ./LLM_input\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIG: OUTPUT SETUP\n",
    "# ---------------------------------------------------------\n",
    "INPUT_DIR = \"./LLM_input\"\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. GATHER DATA FROM MEMORY\n",
    "# ---------------------------------------------------------\n",
    "# We assume these variables exist from your previous cells:\n",
    "# - summary (Baseline)\n",
    "# - ets_hospital_summary (ETS)\n",
    "# - results_df (Global LGBM)\n",
    "# - bucket_df (Segmented LGBM buckets)\n",
    "# - weighted_df (Segmented LGBM weighted)\n",
    "# - topk (SHAP top features, optional)\n",
    "\n",
    "data_packet = {}\n",
    "\n",
    "def safe_save(df, filename):\n",
    "    \"\"\"Saves DataFrame to CSV and adds to packet list\"\"\"\n",
    "    if df is not None and isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        path = os.path.join(INPUT_DIR, filename)\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"[Saved] {filename}\")\n",
    "        return df.to_csv(index=False) # Return string for direct prompt usage later\n",
    "    return None\n",
    "\n",
    "print(\"PREPARING CONTEXT FOR DEEPSEEK...\\n\")\n",
    "\n",
    "# Save Baseline\n",
    "data_packet['baseline'] = safe_save(globals().get('summary'), \"baseline_metrics.csv\")\n",
    "\n",
    "# Save ETS\n",
    "data_packet['ets'] = safe_save(globals().get('ets_hospital_summary'), \"ets_metrics.csv\")\n",
    "\n",
    "# Save Global ML\n",
    "data_packet['ml_global'] = safe_save(globals().get('results_df'), \"ml_global_metrics.csv\")\n",
    "\n",
    "# Save Segmented ML\n",
    "data_packet['ml_segmented_buckets'] = safe_save(globals().get('bucket_df'), \"ml_segmented_buckets.csv\")\n",
    "data_packet['ml_segmented_weighted'] = safe_save(globals().get('weighted_df'), \"ml_segmented_weighted.csv\")\n",
    "\n",
    "# Save Interpretability (SHAP)\n",
    "# Note: 'topk' is the variable name from your SHAP cell\n",
    "data_packet['shap_drivers'] = safe_save(globals().get('topk'), \"shap_top_drivers.csv\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. CREATE META-CONTEXT\n",
    "# ---------------------------------------------------------\n",
    "context_note = {\n",
    "    \"project_scope\": \"Hospital Capacity Planning (Aggregated Time Series)\",\n",
    "    \"dataset\": \"hospital_dataset.tsf\",\n",
    "    \"horizons_months\": [6, 12],\n",
    "    \"constraints\": [\n",
    "        \"Do not forecast values.\",\n",
    "        \"Compare models based on MAE (robustness) and RMSE (outlier penalty).\",\n",
    "        \"Explain WHY segmented models might outperform global ones using the provided metrics.\"\n",
    "    ],\n",
    "    \"generated_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(os.path.join(INPUT_DIR, \"context.json\"), \"w\") as f:\n",
    "    json.dump(context_note, f, indent=2)\n",
    "\n",
    "print(\"\\n✅ Data successfully saved to ./LLM_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f876e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Contacting DeepSeek API...\n",
      "--------------------------------------------------------------------------------\n",
      "**1. Executive Summary**  \n",
      "Segmented modeling by hospital size dramatically improves forecast accuracy for small and medium hospitals, but a global ML model fails to capture the volatility of large hospitals, resulting in high errors. The weighted average of segmented ML models still underperforms classical ETS, which remains the best overall approach for this dataset.\n",
      "\n",
      "**2. Model Leaderboard**  \n",
      "For the 6-month horizon (MAE / RMSE):  \n",
      "- **Seasonal Naive**: 21.82 / 26.01  \n",
      "- **ETS**: 18.59 / 21.78  \n",
      "- **Segmented ML (Weighted)**: 16.46 / 52.37  \n",
      "\n",
      "For the 12-month horizon:  \n",
      "- **Seasonal Naive**: 21.79 / 27.02  \n",
      "- **ETS**: 20.49 / 24.42  \n",
      "- **Segmented ML (Weighted)**: 16.84 / 52.30  \n",
      "\n",
      "**Interpretation**: ETS outperforms Seasonal Naive on both MAE and RMSE, indicating better trend and seasonality capture. The segmented ML model has a lower MAE than ETS, but its RMSE is more than double, signaling high error variance—driven primarily by poor performance on large hospitals.\n",
      "\n",
      "**3. Why Segmentation Matters**  \n",
      "The ML metrics by bucket reveal why a single global model is insufficient:  \n",
      "- **Small hospitals**: MAE ~3.6–3.7, RMSE ~4.8–4.9 (excellent accuracy)  \n",
      "- **Medium hospitals**: MAE ~6.3–6.4, RMSE ~8.6–8.8 (good accuracy)  \n",
      "- **Large hospitals**: MAE ~39, RMSE ~89 (very poor accuracy)  \n",
      "\n",
      "Large hospitals exhibit higher volatility and complex patterns that the current ML features fail to model effectively, inflating the weighted RMSE. Segmentation allows us to tailor models to each group’s behavior, but the large-hospital model requires refinement.\n",
      "\n",
      "**4. Key Drivers**  \n",
      "SHAP analysis shows distinct driver patterns by hospital size:  \n",
      "- **Large hospitals**: Strongly driven by **recent trends** (lag_1 and roll_mean_3 are top features, with combined importance >65%). This suggests short-term autocorrelation dominates their forecasts.  \n",
      "- **Medium hospitals**: Balanced influence from recent trends (lag_1, roll_mean_3) and **longer-term seasonality** (roll_mean_12).  \n",
      "- **Small hospitals**: Primarily driven by **long-term averages** (roll_mean_12 is the top feature), indicating more stable, seasonal behavior.  \n",
      "\n",
      "This explains why a one-size-fits-all ML model struggles: large hospitals need more emphasis on recent lags, while small hospitals rely on smoothed historical averages.\n",
      "\n",
      "**5. Strategic Recommendation**  \n",
      "Based solely on the data:  \n",
      "- **Use ETS for operational planning** across all hospitals. It provides the best balance of accuracy (low MAE) and reliability (low RMSE), without the extreme errors seen in the ML approach.  \n",
      "- **Do not deploy the segmented ML model** in its current form, as the high RMSE for large hospitals poses significant risk for capacity planning.  \n",
      "- **Next steps**: Investigate large-hospital volatility with additional features (e.g., external factors, finer-grained time series) or consider hybrid models (e.g., ETS for large hospitals, ML for small/medium).  \n",
      "\n",
      "*Note: All recommendations are derived from the provided metrics and SHAP analysis.*\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ Report saved to: ./Deepseek_results\\hospital_forecast_narrative.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIG: API & OUTPUT\n",
    "# ---------------------------------------------------------\n",
    "# REPLACE WITH YOUR ACTUAL KEY\n",
    "DEEPSEEK_API_KEY = \"add_key_here\" \n",
    "\n",
    "OUTPUT_DIR = \"./Deepseek_results\"\n",
    "INPUT_DIR = \"./LLM_input\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. LOAD CONTEXT\n",
    "# ---------------------------------------------------------\n",
    "def read_file_content(filename):\n",
    "    path = os.path.join(INPUT_DIR, filename)\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            return f.read()\n",
    "    return \"Data not found.\"\n",
    "\n",
    "context_str = f\"\"\"\n",
    "PROJECT METADATA:\n",
    "{read_file_content('context.json')}\n",
    "\n",
    "BASELINE METRICS (Seasonal Naive):\n",
    "{read_file_content('baseline_metrics.csv')}\n",
    "\n",
    "CLASSICAL METRICS (ETS):\n",
    "{read_file_content('ets_metrics.csv')}\n",
    "\n",
    "ML METRICS (Global LightGBM):\n",
    "{read_file_content('ml_global_metrics.csv')}\n",
    "\n",
    "ML METRICS (Segmented LightGBM - by size bucket):\n",
    "{read_file_content('ml_segmented_buckets.csv')}\n",
    "\n",
    "ML METRICS (Segmented LightGBM - Weighted Average):\n",
    "{read_file_content('ml_segmented_weighted.csv')}\n",
    "\n",
    "KEY DRIVERS (SHAP Importance):\n",
    "{read_file_content('shap_top_drivers.csv')}\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. CONSTRUCT PROMPT\n",
    "# ---------------------------------------------------------\n",
    "system_prompt = \"\"\"You are a Senior Data Science Lead presenting to Hospital Stakeholders.\n",
    "Your goal is to interpret the provided forecasting results.\n",
    "\n",
    "STRUCTURE YOUR RESPONSE AS FOLLOWS:\n",
    "1. **Executive Summary**: The single most important finding (e.g., \"Segmented models reduced error by X% compared to baseline...\").\n",
    "2. **Model Leaderboard**: Compare Seasonal Naive vs. ETS vs. ML. Use specific numbers (MAE/RMSE).\n",
    "3. **Why Segmentation Matters**: Explain the difference in performance between Small vs. Large hospitals based on the metrics.\n",
    "4. **Key Drivers**: Use the SHAP data to explain what drives the forecast (e.g., \"Large hospitals are driven by recent trends (lag_1), while smaller ones depend on yearly averages\").\n",
    "5. **Strategic Recommendation**: Based *only* on the data, what should the planning team use?\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Here is the experimental data from our latest run on the Hospital Dataset.\n",
    "Please generate the report.\n",
    "\n",
    "DATA CONTEXT:\n",
    "{context_str}\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. CALL DEEPSEEK API\n",
    "# ---------------------------------------------------------\n",
    "print(\"⏳ Contacting DeepSeek API...\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DEEPSEEK_API_KEY, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # or \"deepseek-reasoner\" for Chain of Thought\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.3, # Keep it factual\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    narrative = response.choices[0].message.content\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4. SAVE RESULT\n",
    "    # ---------------------------------------------------------\n",
    "    out_path = os.path.join(OUTPUT_DIR, \"hospital_forecast_narrative.md\")\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(narrative)\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(narrative)\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"\\n✅ Report saved to: {out_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ API Error: {e}\")\n",
    "    print(\"Check your API key and internet connection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp3env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
